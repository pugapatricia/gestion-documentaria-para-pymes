{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f3a71b3b",
      "metadata": {
        "id": "f3a71b3b"
      },
      "source": [
        "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pugapatricia/gestion-documentaria-para-pymes/blob/main/etiquetado/Etiquetado_openai.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5bcb24e",
      "metadata": {
        "id": "e5bcb24e"
      },
      "source": [
        "[![Ver en GitHub](https://img.shields.io/badge/GitHub-Repo-black?logo=github)](https://github.com/pugapatricia/gestion-documentaria-para-pymes/tree/main/etiquetado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importaciones"
      ],
      "metadata": {
        "id": "H1Hm8SLMn6sz"
      },
      "id": "H1Hm8SLMn6sz"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3SC0UKYxGlvk",
      "metadata": {
        "id": "3SC0UKYxGlvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3363bb0a-d313-4513-d08e-6a24927ed9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q PyPDF2 python-docx openpyxl python-pptx xlrd transformers office365-rest-python-client msal requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "mdG952zUC6cM",
      "metadata": {
        "id": "mdG952zUC6cM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "from PyPDF2 import PdfReader\n",
        "import docx\n",
        "import openpyxl\n",
        "from pptx import Presentation\n",
        "import xlrd\n",
        "from transformers import pipeline\n",
        "from office365.sharepoint.client_context import ClientContext\n",
        "from office365.runtime.auth.user_credential import UserCredential\n",
        "import os\n",
        "import requests\n",
        "import msal\n",
        "import csv\n",
        "import getpass\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ptKdGUIiEaHz",
      "metadata": {
        "id": "ptKdGUIiEaHz"
      },
      "source": [
        "# Configuraci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = getpass.getpass(\"Introduce tu OpenAI API Key: \")\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxjzqXSLYxov",
        "outputId": "025b02fa-b0aa-4bf9-d98d-c96115ab3249"
      },
      "id": "oxjzqXSLYxov",
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduce tu OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "UAkFWDSoEgGa",
      "metadata": {
        "id": "UAkFWDSoEgGa"
      },
      "outputs": [],
      "source": [
        "CLIENT_ID = \"e3f2393e-7348-47d1-9c64-8d8efe6a5e95\"  # tu nuevo Client ID\n",
        "AUTHORITY = \"https://login.microsoftonline.com/consumers\"\n",
        "SCOPE = [\"User.Read\", \"Files.ReadWrite\"]\n",
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"pptx\", \"txt\", \"csv\"}\n",
        "url = \"https://graph.microsoft.com/v1.0/me/drive/root:/Etiquetados:/children\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lKu0-R84Ei__",
      "metadata": {
        "id": "lKu0-R84Ei__"
      },
      "source": [
        "# Conecci√≥n con OneDrive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4SfZ6bYUEpzF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SfZ6bYUEpzF",
        "outputId": "bba9937f-e8b4-4361-ce0f-f795b73743ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To sign in, use a web browser to open the page https://www.microsoft.com/link and enter the code UVJ6L68F to authenticate.\n"
          ]
        }
      ],
      "source": [
        "app = msal.PublicClientApplication(CLIENT_ID, authority=AUTHORITY)\n",
        "\n",
        "flow = app.initiate_device_flow(scopes=SCOPE)\n",
        "if \"user_code\" not in flow:\n",
        "    raise Exception(\"No se pudo iniciar el device flow. Revisa tu configuraci√≥n en Azure.\")\n",
        "\n",
        "print(flow[\"message\"])  # üëâ Copia el c√≥digo en https://microsoft.com/devicelogin\n",
        "result = app.acquire_token_by_device_flow(flow)\n",
        "\n",
        "if \"access_token\" not in result:\n",
        "    raise Exception(f\"Error autenticaci√≥n: {result.get('error_description')}\")\n",
        "\n",
        "access_token = result[\"access_token\"]\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Llamada a la API con tu token de acceso\n",
        "resp = requests.get(url, headers=headers)\n",
        "if resp.status_code != 200:\n",
        "    raise Exception(f\"Error al obtener archivos: {resp.text}\")\n",
        "data = resp.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funciones"
      ],
      "metadata": {
        "id": "IYoSk_6voooa"
      },
      "id": "IYoSk_6voooa"
    },
    {
      "cell_type": "markdown",
      "id": "fGLBYpx2FJqW",
      "metadata": {
        "id": "fGLBYpx2FJqW"
      },
      "source": [
        "Clasificador OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "XqETdx4wFL4e",
      "metadata": {
        "id": "XqETdx4wFL4e"
      },
      "outputs": [],
      "source": [
        "etiquetas = [\n",
        "    \"contrato\", \"arrendamiento\", \"vivienda\", \"modelo\", \"legal\", \"inmobiliaria\",\n",
        "    \"admitidos\", \"cursos\", \"monogr√°ficos\", \"educaci√≥n\", \"registro\",\n",
        "    \"reserva\", \"inmueble\", \"alquiler\", \"NDA\", \"confidencialidad\", \"acuerdo\", \"plantilla\",\n",
        "    \"unilateral\", \"UE\", \"OEPM\", \"presentaci√≥n\", \"anexo\", \"personal\", \"informe\",\n",
        "    \"an√°lisis\", \"estados financieros\", \"contabilidad\", \"proyecto\",\n",
        "    \"biblioteca\", \"datos\", \"csv\", \"inventario\", \"opci√≥n de compra\", \"freelancer\",\n",
        "    \"formulario\", \"registro\", \"administrativo\", \"prueba\", \"test\", \"justificante\",\n",
        "    \"bachillerato\", \"HH-CCSS\", \"temporada\", \"finca r√∫stica\", \"rescisi√≥n\",\n",
        "    \"empresa\", \"acad√©mico\", \"pr√≥rroga\", \"proyecto\",\n",
        "    \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\",\n",
        "    \"2020\", \"2021\", \"2022\", \"2023\", \"2024\", \"2025\", \"2026\", \"2027\", \"2028\", \"2029\", \"2030\"\n",
        "]\n",
        "\n",
        "def limpiar_texto(texto: str) -> str:\n",
        "    if not texto:\n",
        "        return \"\"\n",
        "    texto = re.sub(r'\\d+\\n', '', texto)       # eliminar numeraci√≥n de p√°gina\n",
        "    texto = re.sub(r'\\s+', ' ', texto)        # unir saltos de l√≠nea\n",
        "    # conservar comas, puntos, guiones y par√©ntesis\n",
        "    texto = re.sub(r'[^a-zA-Z√°√©√≠√≥√∫√º√±0-9\\s,.\\-()/:]', '', texto)\n",
        "    return texto.strip()\n",
        "\n",
        "\n",
        "def etiquetar_texto(texto, max_etiquetas=5, modelo=\"gpt-5-mini\"):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analiza el siguiente texto y selecciona hasta {max_etiquetas} etiquetas de la lista dada\n",
        "    que mejor representen los temas principales. No inventes etiquetas fuera de la lista.\n",
        "\n",
        "    Lista de etiquetas disponibles: {', '.join(etiquetas)}\n",
        "\n",
        "    Texto: \\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
        "\n",
        "    Devuelve solo las etiquetas seleccionadas, separadas por comas.\n",
        "    \"\"\"\n",
        "\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=150,\n",
        "        temperature=1\n",
        "    )\n",
        "\n",
        "    etiquetas = respuesta.choices[0].message.content.strip()\n",
        "    # Filtrar solo etiquetas v√°lidas\n",
        "    etiquetas = [e.strip() for e in etiquetas.split(\",\") if e.strip() in etiquetas]\n",
        "    return etiquetas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lector de documentos"
      ],
      "metadata": {
        "id": "SVuMqyREoznw"
      },
      "id": "SVuMqyREoznw"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "RTR5h05bFUDm",
      "metadata": {
        "id": "RTR5h05bFUDm"
      },
      "outputs": [],
      "source": [
        "def leer_pdf(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    reader = PdfReader(io.BytesIO(contenido))\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            texto += page_text + \"\\n\"\n",
        "    # Aplicar l√≠mite de palabras al final\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_docx(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    doc = docx.Document(io.BytesIO(contenido))\n",
        "    # P√°rrafos\n",
        "    for p in doc.paragraphs:\n",
        "        if p.text.strip():\n",
        "            texto += p.text + \"\\n\"\n",
        "    # Tablas\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            row_text = \" \".join([cell.text for cell in row.cells if cell.text.strip()])\n",
        "            if row_text:\n",
        "                texto += row_text + \"\\n\"\n",
        "    # Aplicar l√≠mite al final\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_excel(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    wb = openpyxl.load_workbook(io.BytesIO(contenido), data_only=True, read_only=True)\n",
        "    for sheet in wb.worksheets:\n",
        "        for row in sheet.iter_rows(values_only=True):\n",
        "            row_text = \" \".join([str(cell) for cell in row if cell])\n",
        "            if row_text:\n",
        "                texto += row_text + \"\\n\"\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_xls(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    temp_file = \"temp.xls\"\n",
        "    with open(temp_file, \"wb\") as f:\n",
        "        f.write(contenido)\n",
        "    wb = xlrd.open_workbook(temp_file)\n",
        "    for sheet in wb.sheets():\n",
        "        for row_idx in range(sheet.nrows):\n",
        "            row = sheet.row_values(row_idx)\n",
        "            row_text = \" \".join([str(cell) for cell in row if cell])\n",
        "            if row_text:\n",
        "                texto += row_text + \"\\n\"\n",
        "    os.remove(temp_file)\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_pptx(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    temp_file = \"temp.pptx\"\n",
        "    with open(temp_file, \"wb\") as f:\n",
        "        f.write(contenido)\n",
        "    prs = Presentation(temp_file)\n",
        "    for slide in prs.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\") and shape.text.strip():\n",
        "                texto += shape.text + \"\\n\"\n",
        "    os.remove(temp_file)\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_txt_csv(contenido, limite_palabras=None):\n",
        "    texto = contenido.decode(\"utf-8\", errors=\"ignore\")\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_archivo(nombre, contenido, limite_palabras=None):\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext == \"pdf\":\n",
        "        return leer_pdf(contenido, limite_palabras)\n",
        "    elif ext == \"docx\":\n",
        "        return leer_docx(contenido, limite_palabras)\n",
        "    elif ext == \"xlsx\":\n",
        "        return leer_excel(contenido, limite_palabras)\n",
        "    elif ext == \"xls\":\n",
        "        return leer_xls(contenido, limite_palabras)\n",
        "    elif ext == \"pptx\":\n",
        "        return leer_pptx(contenido, limite_palabras)\n",
        "    elif ext in {\"txt\", \"csv\"}:\n",
        "        return leer_txt_csv(contenido, limite_palabras)\n",
        "    else:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = leer_archivo(nombre, file_bytes, limite_palabras)\n",
        "\n",
        "# Mostrar las primeras 500-1000 palabras para revisar\n",
        "print(f\"\\n--- Texto extra√≠do ({nombre}) ---\")\n",
        "print(texto[:1000])  # Ajusta la cantidad seg√∫n lo que quieras ver\n",
        "print(\"--- Fin del texto extra√≠do ---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmb_8gES2_w9",
        "outputId": "e73670af-c1ea-49b8-f602-7fdbf36de2b1"
      },
      "id": "mmb_8gES2_w9",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Texto extra√≠do (2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx) ---\n",
            "DOCUMENTO DE RESERVA DE INMUEBLE EN ARRENDAMIENTO En [lugar], [fecha] REUNIDOS De una parte, D./D√±a. [nombre y apellidos del propietario], mayor de edad, de nacionalidad [nacionalidad], con domicilio en [domicilio] y DNI/NIE/pasaporte de su nacionalidad n√∫mero [n√∫mero identificaci√≥n]. Act√∫a en su propio nombre y representaci√≥n. En adelante, la ‚ÄúParte Propietaria‚Äù. Y de otra, D./D√±a. [nombre y apellidos inquilino 1], mayor de edad, de nacionalidad [nacionalidad], con domicilio en [domicilio] y DNI/NIE/pasaporte de su nacionalidad n√∫mero [n√∫mero identificaci√≥n]. Act√∫a en su propio nombre y representaci√≥n. D./D√±a. [nombre y apellidos inquilino 2], mayor de edad, de nacionalidad [nacionalidad], con domicilio en [domicilio] y DNI/NIE/pasaporte de su nacionalidad n√∫mero [n√∫mero identificaci√≥n]. Act√∫a en su propio nombre y representaci√≥n. En adelante, la ‚ÄúParte Reservante‚Äù. La Parte Propietaria y la Parte Reservante ser√°n denominadas conjuntamente como las ‚ÄúPartes‚Äù, y a cada una de ellas, ind\n",
            "--- Fin del texto extra√≠do ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eFJR7GKaFaRk",
      "metadata": {
        "id": "eFJR7GKaFaRk"
      },
      "source": [
        "# Leer archivos de OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "r8dBhXbyFfLP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8dBhXbyFfLP",
        "outputId": "6fb706d3-397a-43c2-e330-5d73e1f7fb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando archivo: 11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf\n",
            "11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf ‚Üí []\n",
            "Procesando archivo: 2016-admitidos_Segundo ciclo- Cursos monogr√°ficos.xls\n",
            "2016-admitidos_Segundo ciclo- Cursos monogr√°ficos.xls ‚Üí []\n",
            "Procesando archivo: 2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx\n",
            "2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx ‚Üí []\n",
            "Resultados guardados en etiquetas_onedrive.csv\n"
          ]
        }
      ],
      "source": [
        "# Limitar a los primeros 3 archivos permitidos\n",
        "archivos_a_procesar = archivos_permitidos[:3]\n",
        "\n",
        "if archivos_a_procesar:\n",
        "    resultados = {}\n",
        "\n",
        "    for item in archivos_a_procesar:\n",
        "        nombre = item[\"name\"]\n",
        "        download_url = item[\"@microsoft.graph.downloadUrl\"]\n",
        "\n",
        "        print(f\"Procesando archivo: {nombre}\")\n",
        "\n",
        "        # Descargar contenido del archivo\n",
        "        file_bytes = requests.get(download_url).content\n",
        "\n",
        "        # Definir l√≠mite de palabras\n",
        "        limite_palabras = 500  # Ajustable\n",
        "\n",
        "        # Leer el archivo seg√∫n su extensi√≥n y l√≠mite de palabras\n",
        "        texto = leer_archivo(nombre, file_bytes, limite_palabras)\n",
        "\n",
        "        # --- LIMPIEZA DEL TEXTO ---\n",
        "        texto = limpiar_texto(texto)\n",
        "\n",
        "        # Etiquetar texto si no est√° vac√≠o\n",
        "        if texto:\n",
        "            etiquetas_detectadas = etiquetar_texto(texto)\n",
        "        else:\n",
        "            etiquetas_detectadas = []\n",
        "\n",
        "        resultados[nombre] = etiquetas_detectadas\n",
        "\n",
        "        # Mostrar resultado\n",
        "        print(f\"{nombre} ‚Üí {etiquetas_detectadas}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MTA1Lj9jFgy1",
      "metadata": {
        "id": "MTA1Lj9jFgy1"
      },
      "source": [
        "#Guardar resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LG0oigjOFgiy",
      "metadata": {
        "id": "LG0oigjOFgiy"
      },
      "outputs": [],
      "source": [
        "    # Guardar todos los resultados en CSV\n",
        "    with open(\"etiquetas_onedrive.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Archivo\", \"Etiquetas\"])\n",
        "        for nombre, etiquetas_detectadas in resultados.items():\n",
        "            etiquetas_str = \", \".join(etiquetas_detectadas) if etiquetas_detectadas else \"Sin etiquetas\"\n",
        "            writer.writerow([nombre, etiquetas_str])\n",
        "\n",
        "    print(\"Resultados guardados en etiquetas_onedrive.csv\")\n",
        "\n",
        "else:\n",
        "    print(\"No se encontraron archivos permitidos para procesar.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codigo para cargar en la etiqueta de descripcion en onedrive"
      ],
      "metadata": {
        "id": "PqEIKeX8zwJm"
      },
      "id": "PqEIKeX8zwJm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3005d25",
      "metadata": {
        "id": "e3005d25"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# ============================\n",
        "# Configuraci√≥n\n",
        "# ============================\n",
        "json_path = \"etiquetas_onedrive.json\"\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Carpeta objetivo en OneDrive\n",
        "carpeta_objetivo = \"Etiquetados\"\n",
        "\n",
        "# ============================\n",
        "# Cargar JSON de etiquetas\n",
        "# ============================\n",
        "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    etiquetas_data = json.load(f)\n",
        "\n",
        "# ============================\n",
        "# Aplicar etiquetas en la descripci√≥n\n",
        "# ============================\n",
        "for archivo, etiquetas in etiquetas_data.items():\n",
        "    if not etiquetas:\n",
        "        continue\n",
        "\n",
        "    # Buscar archivo en OneDrive\n",
        "    url_file = f\"https://graph.microsoft.com/v1.0/me/drive/root:/{carpeta_objetivo}/{archivo}\"\n",
        "    resp_file = requests.get(url_file, headers=headers)\n",
        "\n",
        "    if resp_file.status_code != 200:\n",
        "        print(f\"‚ö†Ô∏è No se encontr√≥ {archivo} en OneDrive\")\n",
        "        continue\n",
        "\n",
        "    file_id = resp_file.json()[\"id\"]\n",
        "\n",
        "    # Guardamos etiquetas en el campo \"description\"\n",
        "    url_update = f\"https://graph.microsoft.com/v1.0/me/drive/items/{file_id}\"\n",
        "    payload = {\"description\": \", \".join(etiquetas)}\n",
        "\n",
        "    response_update = requests.patch(\n",
        "        url_update,\n",
        "        headers={**headers, \"Content-Type\": \"application/json\"},\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response_update.status_code in [200, 204]:\n",
        "        print(f\"‚úÖ Etiquetas {etiquetas} aplicadas a {archivo} en la descripci√≥n\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Error al actualizar {archivo}: {response_update.text}\")\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}