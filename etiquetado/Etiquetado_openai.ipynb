{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f3a71b3b",
      "metadata": {
        "id": "f3a71b3b"
      },
      "source": [
        "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pugapatricia/gestion-documentaria-para-pymes/blob/main/etiquetado/Etiquetado_openai.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5bcb24e",
      "metadata": {
        "id": "e5bcb24e"
      },
      "source": [
        "[![Ver en GitHub](https://img.shields.io/badge/GitHub-Repo-black?logo=github)](https://github.com/pugapatricia/gestion-documentaria-para-pymes/tree/main/etiquetado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importaciones"
      ],
      "metadata": {
        "id": "H1Hm8SLMn6sz"
      },
      "id": "H1Hm8SLMn6sz"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3SC0UKYxGlvk",
      "metadata": {
        "id": "3SC0UKYxGlvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2dce15a-7d3f-4d18-9679-4c2cb61f2e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q PyPDF2 python-docx openpyxl python-pptx xlrd transformers office365-rest-python-client msal requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmqEKYdgcraW",
        "outputId": "d4e875b8-cca9-4755-8253-55870b587577"
      },
      "id": "jmqEKYdgcraW",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "mdG952zUC6cM",
      "metadata": {
        "id": "mdG952zUC6cM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "from PyPDF2 import PdfReader\n",
        "import docx\n",
        "import openpyxl\n",
        "from pptx import Presentation\n",
        "import xlrd\n",
        "from transformers import pipeline\n",
        "from office365.sharepoint.client_context import ClientContext\n",
        "from office365.runtime.auth.user_credential import UserCredential\n",
        "import os\n",
        "import requests\n",
        "import msal\n",
        "import csv\n",
        "import getpass\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ptKdGUIiEaHz",
      "metadata": {
        "id": "ptKdGUIiEaHz"
      },
      "source": [
        "# Configuraci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = getpass.getpass(\"Introduce tu OpenAI API Key: \")\n",
        "client = OpenAI(api_key=api_key)\n",
        "token = getpass.getpass(\"Introduce tu GitHub token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxjzqXSLYxov",
        "outputId": "1f279435-765f-427b-b149-a9c45ff0bee4"
      },
      "id": "oxjzqXSLYxov",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduce tu OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Introduce tu GitHub token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "UAkFWDSoEgGa",
      "metadata": {
        "id": "UAkFWDSoEgGa"
      },
      "outputs": [],
      "source": [
        "CLIENT_ID = \"e3f2393e-7348-47d1-9c64-8d8efe6a5e95\"  # tu nuevo Client ID\n",
        "AUTHORITY = \"https://login.microsoftonline.com/consumers\"\n",
        "SCOPE = [\"User.Read\", \"Files.ReadWrite\"]\n",
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"pptx\", \"txt\", \"csv\"}\n",
        "url = \"https://graph.microsoft.com/v1.0/me/drive/root:/Etiquetados:/children\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"marcomendieta08@gmail.com\"\n",
        "!git config --global user.name \"marcomendieta08\"\n",
        "!git clone https://github.com/pugapatricia/gestion-documentaria-para-pymes.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebbWZ-U4c063",
        "outputId": "96a412fc-8721-4606-826f-c080ddf86269"
      },
      "id": "ebbWZ-U4c063",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gestion-documentaria-para-pymes' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lKu0-R84Ei__",
      "metadata": {
        "id": "lKu0-R84Ei__"
      },
      "source": [
        "# Conecci√≥n con OneDrive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4SfZ6bYUEpzF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SfZ6bYUEpzF",
        "outputId": "e7221384-4931-47b3-df1c-eacb6f70ac42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To sign in, use a web browser to open the page https://www.microsoft.com/link and enter the code GAX7HSWH to authenticate.\n"
          ]
        }
      ],
      "source": [
        "app = msal.PublicClientApplication(CLIENT_ID, authority=AUTHORITY)\n",
        "\n",
        "flow = app.initiate_device_flow(scopes=SCOPE)\n",
        "if \"user_code\" not in flow:\n",
        "    raise Exception(\"No se pudo iniciar el device flow. Revisa tu configuraci√≥n en Azure.\")\n",
        "\n",
        "print(flow[\"message\"])  # üëâ Copia el c√≥digo en https://microsoft.com/devicelogin\n",
        "result = app.acquire_token_by_device_flow(flow)\n",
        "\n",
        "if \"access_token\" not in result:\n",
        "    raise Exception(f\"Error autenticaci√≥n: {result.get('error_description')}\")\n",
        "\n",
        "access_token = result[\"access_token\"]\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Llamada a la API con tu token de acceso\n",
        "resp = requests.get(url, headers=headers)\n",
        "if resp.status_code != 200:\n",
        "    raise Exception(f\"Error al obtener archivos: {resp.text}\")\n",
        "data = resp.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funciones"
      ],
      "metadata": {
        "id": "IYoSk_6voooa"
      },
      "id": "IYoSk_6voooa"
    },
    {
      "cell_type": "markdown",
      "id": "fGLBYpx2FJqW",
      "metadata": {
        "id": "fGLBYpx2FJqW"
      },
      "source": [
        "Clasificador OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticketsTXT = \"https://raw.githubusercontent.com/pugapatricia/gestion-documentaria-para-pymes/refs/heads/main/etiquetado/tickers.txt\"\n",
        "response = requests.get(ticketsTXT)\n",
        "etiquetas = response.text.strip().split(\", \")\n",
        "print(etiquetas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzpe4_GWeL5j",
        "outputId": "a9bf2917-bb22-4883-f11b-2717bb56a61d"
      },
      "id": "yzpe4_GWeL5j",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tauromaquia', 'pasaporte', 'se√±al', 'medioambiente', 'universidad', 'arqueolog√≠a', 'financiero', 'contadur√≠a', 'restituci√≥n', 'materias', 'regresi√≥n', 'extranjero', 'renta', 'an√°lisis', 'puente', 'servicios', 'inquilino', 'optativa', 'arrendador', 'seguridad', 'notificaciones', 'vigilancia', 'depreciaci√≥n', 'empresa', 'geograf√≠a', 'monogr√°ficos', 'estancia', 'balance', 'divulgaci√≥n', 'autorizaci√≥n', 'master', 'madrid', 'interpretaci√≥n', 'ingresos', 'm√©todos', 'fuentes', 'idiomas', 'silvopastoril', 'extranjer√≠a', 'receptor', 'proyecto', 'inter√©s', 'apalancamiento', 'propiedad', 'incumplimiento', 'estudios', 'nie', 'datascience', 'complutense', 'mediaci√≥n', 'firma', 'liquidez', 'valoracion', 'desalojo', 'compraventa', 'alquiler', 'sociales', 'jarama', 'partes', 'contrato', 'tasas', 'humanidades', 'estudiantes', 'activos', 'actividad', 'pasivos', 'financieros', 'registro', 'divulgador', 'cesi√≥n', 'poes√≠a', 'temporada', 'documentaci√≥n', 'rentabilidad', 'comisiones', 'flujodecaja', 'patrimonio', 'proyecci√≥n', 'arganda', '2016-2017', 'indicadores', 'suministros', 'arrendamiento', 'cursos', 'empaques', 'devoluci√≥n', 'nda', 'costos', 'admitidos', 'informaci√≥n', 'solicitud', 'panama', 'matr√≠cula', 'reserva', 'cartera', 'vivienda', 'habitaci√≥n', 'mendieta', 'consorcio', 'autorizacion', 'acuerdo', 'curso', 'arrendatario', 'egresos', 'duraci√≥n', 'simulaci√≥n', 'decisiones', 'jurisdicci√≥n', 'prorroga', 'transporte', 'eva', 'rescisi√≥n', 'secreto', 'pr√≥rroga', 'van', 'obligaciones', 'contabilidad', 'm√°ster', 'inventarios', 'env√≠os', 'tir', 'confidencialidad', 'historia', 'cl√°usulas', 'inversi√≥n', 'vino', 'amortizaci√≥n', 'penalizaciones', 'propietario', 'astrof√≠sica', 'cr√©ditos', 'alumnos', 'inmueble', 'batalla', 'cultivo', 'finca', 'fianza', 'estados', 'flujo', 'visado', 'endeudamiento', 'subarriendo', 'propiedadintelectual', 'comparaci√≥n', 'seguro', 'proyeccion', 'matem√°ticas', 'financiera', 'lau', 'archivo', 'cauca', 'marco', 'arte', 'bachillerato']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lector de documentos"
      ],
      "metadata": {
        "id": "SVuMqyREoznw"
      },
      "id": "SVuMqyREoznw"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "RTR5h05bFUDm",
      "metadata": {
        "id": "RTR5h05bFUDm"
      },
      "outputs": [],
      "source": [
        "def leer_pdf(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    reader = PdfReader(io.BytesIO(contenido))\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            texto += page_text + \"\\n\"\n",
        "    # Aplicar l√≠mite de palabras al final\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_docx(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    doc = docx.Document(io.BytesIO(contenido))\n",
        "    # P√°rrafos\n",
        "    for p in doc.paragraphs:\n",
        "        if p.text.strip():\n",
        "            texto += p.text + \"\\n\"\n",
        "    # Tablas\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            row_text = \" \".join([cell.text for cell in row.cells if cell.text.strip()])\n",
        "            if row_text:\n",
        "                texto += row_text + \"\\n\"\n",
        "    # Aplicar l√≠mite al final\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_excel(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    wb = openpyxl.load_workbook(io.BytesIO(contenido), data_only=True, read_only=True)\n",
        "    for sheet in wb.worksheets:\n",
        "        for row in sheet.iter_rows(values_only=True):\n",
        "            row_text = \" \".join([str(cell) for cell in row if cell])\n",
        "            if row_text:\n",
        "                texto += row_text + \"\\n\"\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_xls(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    temp_file = \"temp.xls\"\n",
        "    with open(temp_file, \"wb\") as f:\n",
        "        f.write(contenido)\n",
        "    wb = xlrd.open_workbook(temp_file)\n",
        "    for sheet in wb.sheets():\n",
        "        for row_idx in range(sheet.nrows):\n",
        "            row = sheet.row_values(row_idx)\n",
        "            row_text = \" \".join([str(cell) for cell in row if cell])\n",
        "            if row_text:\n",
        "                texto += row_text + \"\\n\"\n",
        "    os.remove(temp_file)\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_pptx(contenido, limite_palabras=None):\n",
        "    texto = \"\"\n",
        "    temp_file = \"temp.pptx\"\n",
        "    with open(temp_file, \"wb\") as f:\n",
        "        f.write(contenido)\n",
        "    prs = Presentation(temp_file)\n",
        "    for slide in prs.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\") and shape.text.strip():\n",
        "                texto += shape.text + \"\\n\"\n",
        "    os.remove(temp_file)\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_txt_csv(contenido, limite_palabras=None):\n",
        "    texto = contenido.decode(\"utf-8\", errors=\"ignore\")\n",
        "    if limite_palabras:\n",
        "        texto = \" \".join(texto.split()[:limite_palabras])\n",
        "    return texto\n",
        "\n",
        "def leer_archivo(nombre, contenido, limite_palabras=None):\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext == \"pdf\":\n",
        "        return leer_pdf(contenido, limite_palabras)\n",
        "    elif ext == \"docx\":\n",
        "        return leer_docx(contenido, limite_palabras)\n",
        "    elif ext == \"xlsx\":\n",
        "        return leer_excel(contenido, limite_palabras)\n",
        "    elif ext == \"xls\":\n",
        "        return leer_xls(contenido, limite_palabras)\n",
        "    elif ext == \"pptx\":\n",
        "        return leer_pptx(contenido, limite_palabras)\n",
        "    elif ext in {\"txt\", \"csv\"}:\n",
        "        return leer_txt_csv(contenido, limite_palabras)\n",
        "    else:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "XqETdx4wFL4e",
      "metadata": {
        "id": "XqETdx4wFL4e"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto(texto: str) -> str:\n",
        "    if not texto:\n",
        "        return \"\"\n",
        "    texto = re.sub(r'\\d+\\n', '', texto)       # eliminar numeraci√≥n de p√°gina\n",
        "    texto = re.sub(r'\\s+', ' ', texto)        # unir saltos de l√≠nea\n",
        "    # conservar comas, puntos, guiones y par√©ntesis\n",
        "    texto = re.sub(r'[^a-zA-Z√°√©√≠√≥√∫√º√±0-9\\s,.\\-()/:]', '', texto)\n",
        "    return texto.strip()\n",
        "\n",
        "\n",
        "def etiquetar_texto(texto, etiquetas, max_etiquetas=10, modelo=\"gpt-5-mini\"):\n",
        "    prompt = f\"\"\"\n",
        "    Analiza el siguiente texto y selecciona hasta {max_etiquetas} etiquetas de la lista dada\n",
        "    que mejor representen los temas principales. No inventes etiquetas fuera de la lista.\n",
        "\n",
        "    Lista de etiquetas disponibles: {', '.join(etiquetas)}\n",
        "\n",
        "    Texto: \\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
        "\n",
        "    Devuelve solo las etiquetas seleccionadas, separadas por comas.\n",
        "    \"\"\"\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=400,\n",
        "        temperature=1\n",
        "    )\n",
        "\n",
        "    # Acceder correctamente al contenido\n",
        "    resultado = respuesta.choices[0].message.content.strip()\n",
        "\n",
        "    # Filtrar solo etiquetas v√°lidas\n",
        "    return [e.strip() for e in resultado.split(\",\") if e.strip() in etiquetas]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto_ejemplo = \"La Universidad Complutense de Madrid lanz√≥ un proyecto en datascience para analizar el impacto ambiental en zonas silvopastoriles. Los estudiantes participan usando m√©todos de an√°lisis y regresi√≥n, mientras la administraci√≥n gestiona rentas, contratos, autorizaciones y la rentabilidad de los activos y pasivos. Adem√°s, se recopila documentaci√≥n hist√≥rica y arqueol√≥gica para su divulgaci√≥n, respetando la propiedadintelectual y la confidencialidad de los materiales.\"\n",
        "texto_limpio = limpiar_texto(texto_ejemplo)\n",
        "print(\"Texto limpio:\", texto_limpio)\n",
        "\n",
        "etiquetas_seleccionadas = etiquetar_texto(texto_limpio, etiquetas, max_etiquetas=10)\n",
        "print(\"Etiquetas seleccionadas:\", etiquetas_seleccionadas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm-saIwklW21",
        "outputId": "d4e62331-2b02-4d69-cd58-a107b34a3a03"
      },
      "id": "Vm-saIwklW21",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto limpio: La Universidad Complutense de Madrid lanz√≥ un proyecto en datascience para analizar el impacto ambiental en zonas silvopastoriles. Los estudiantes participan usando m√©todos de an√°lisis y regresi√≥n, mientras la administraci√≥n gestiona rentas, contratos, autorizaciones y la rentabilidad de los activos y pasivos. Adem√°s, se recopila documentaci√≥n hist√≥rica y arqueol√≥gica para su divulgaci√≥n, respetando la propiedadintelectual y la confidencialidad de los materiales.\n",
            "Etiquetas seleccionadas: ['educaci√≥n', 'gesti√≥n', 'finanzas', 'software']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eFJR7GKaFaRk",
      "metadata": {
        "id": "eFJR7GKaFaRk"
      },
      "source": [
        "# Leer archivos de OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "r8dBhXbyFfLP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8dBhXbyFfLP",
        "outputId": "b6c3eec6-06e5-4b3d-9551-7e56a56bd4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando archivo: 11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf\n",
            "11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf ‚Üí ['finanzas', 'gesti√≥n']\n",
            "Procesando archivo: 2016-admitidos_Segundo ciclo- Cursos monogr√°ficos.xls\n",
            "2016-admitidos_Segundo ciclo- Cursos monogr√°ficos.xls ‚Üí ['educaci√≥n', 'gesti√≥n', 'software']\n",
            "Procesando archivo: 2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx\n",
            "2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx ‚Üí ['finanzas', 'gesti√≥n']\n",
            "Procesando archivo: 660d1bfb7c43622a597a4000_Non-disclosure agreement nda template contract.pdf\n",
            "660d1bfb7c43622a597a4000_Non-disclosure agreement nda template contract.pdf ‚Üí []\n",
            "Procesando archivo: Acuerdo_no_Divulgacion_Unilateral_UE.pdf\n",
            "Acuerdo_no_Divulgacion_Unilateral_UE.pdf ‚Üí ['pymes', 'gesti√≥n', 'finanzas']\n",
            "Procesando archivo: Acuerdo-de-Confidencialidad-OEPM.pdf\n",
            "Acuerdo-de-Confidencialidad-OEPM.pdf ‚Üí ['gesti√≥n', 'pymes', 'educaci√≥n']\n",
            "Procesando archivo: AnaLiliana_SuarezHerrera_WelmarFernandoRinconTorres_2018_Anexo1.pptx\n",
            "AnaLiliana_SuarezHerrera_WelmarFernandoRinconTorres_2018_Anexo1.pptx ‚Üí ['finanzas', 'gesti√≥n', 'educaci√≥n', 'pymes']\n",
            "Procesando archivo: Analisis de interpretacion de estados financieros.pptx\n",
            "Analisis de interpretacion de estados financieros.pptx ‚Üí ['finanzas', 'gesti√≥n', 'educaci√≥n']\n"
          ]
        }
      ],
      "source": [
        "archivos_permitidos = [\n",
        "    item for item in data.get(\"value\", [])\n",
        "    if \"folder\" not in item and item[\"name\"].split(\".\")[-1].lower() in ext_permitidas\n",
        "]\n",
        "\n",
        "# Procesar solo los primeros 3 archivos\n",
        "archivos_a_procesar = archivos_permitidos[:8]\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for item in archivos_a_procesar:\n",
        "    nombre = item[\"name\"]\n",
        "    download_url = item[\"@microsoft.graph.downloadUrl\"]\n",
        "\n",
        "    print(f\"Procesando archivo: {nombre}\")\n",
        "\n",
        "    # Descargar contenido del archivo\n",
        "    file_bytes = requests.get(download_url).content\n",
        "\n",
        "    # Leer el archivo seg√∫n su extensi√≥n (sin l√≠mite de palabras si quieres)\n",
        "    texto = leer_archivo(nombre, file_bytes, limite_palabras=None)\n",
        "\n",
        "    # Limpiar el texto\n",
        "    texto_limpio = limpiar_texto(texto)\n",
        "\n",
        "    # Etiquetar solo si hay contenido\n",
        "    if texto_limpio:\n",
        "        etiquetas_detectadas = etiquetar_texto(texto_limpio, etiquetas, max_etiquetas=5)\n",
        "    else:\n",
        "        etiquetas_detectadas = []\n",
        "\n",
        "    resultados[nombre] = etiquetas_detectadas\n",
        "\n",
        "    print(f\"{nombre} ‚Üí {etiquetas_detectadas}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MTA1Lj9jFgy1",
      "metadata": {
        "id": "MTA1Lj9jFgy1"
      },
      "source": [
        "#Guardar resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LG0oigjOFgiy",
      "metadata": {
        "id": "LG0oigjOFgiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "b953ce2e-8b51-4cfd-9c31-121dbeb71700"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3827043340.py, line 11)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3827043340.py\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "    # Guardar todos los resultados en CSV\n",
        "    with open(\"etiquetas_onedrive.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Archivo\", \"Etiquetas\"])\n",
        "        for nombre, etiquetas_detectadas in resultados.items():\n",
        "            etiquetas_str = \", \".join(etiquetas_detectadas) if etiquetas_detectadas else \"Sin etiquetas\"\n",
        "            writer.writerow([nombre, etiquetas_str])\n",
        "\n",
        "    print(\"Resultados guardados en etiquetas_onedrive.csv\")\n",
        "\n",
        "else:\n",
        "    print(\"No se encontraron archivos permitidos para procesar.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codigo para cargar en la etiqueta de descripcion en onedrive"
      ],
      "metadata": {
        "id": "PqEIKeX8zwJm"
      },
      "id": "PqEIKeX8zwJm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3005d25",
      "metadata": {
        "id": "e3005d25"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# ============================\n",
        "# Configuraci√≥n\n",
        "# ============================\n",
        "json_path = \"etiquetas_onedrive.json\"\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Carpeta objetivo en OneDrive\n",
        "carpeta_objetivo = \"Etiquetados\"\n",
        "\n",
        "# ============================\n",
        "# Cargar JSON de etiquetas\n",
        "# ============================\n",
        "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    etiquetas_data = json.load(f)\n",
        "\n",
        "# ============================\n",
        "# Aplicar etiquetas en la descripci√≥n\n",
        "# ============================\n",
        "for archivo, etiquetas in etiquetas_data.items():\n",
        "    if not etiquetas:\n",
        "        continue\n",
        "\n",
        "    # Buscar archivo en OneDrive\n",
        "    url_file = f\"https://graph.microsoft.com/v1.0/me/drive/root:/{carpeta_objetivo}/{archivo}\"\n",
        "    resp_file = requests.get(url_file, headers=headers)\n",
        "\n",
        "    if resp_file.status_code != 200:\n",
        "        print(f\"‚ö†Ô∏è No se encontr√≥ {archivo} en OneDrive\")\n",
        "        continue\n",
        "\n",
        "    file_id = resp_file.json()[\"id\"]\n",
        "\n",
        "    # Guardamos etiquetas en el campo \"description\"\n",
        "    url_update = f\"https://graph.microsoft.com/v1.0/me/drive/items/{file_id}\"\n",
        "    payload = {\"description\": \", \".join(etiquetas)}\n",
        "\n",
        "    response_update = requests.patch(\n",
        "        url_update,\n",
        "        headers={**headers, \"Content-Type\": \"application/json\"},\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response_update.status_code in [200, 204]:\n",
        "        print(f\"‚úÖ Etiquetas {etiquetas} aplicadas a {archivo} en la descripci√≥n\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Error al actualizar {archivo}: {response_update.text}\")\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}