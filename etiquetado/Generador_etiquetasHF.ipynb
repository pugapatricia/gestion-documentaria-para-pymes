{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-KarOQNArIt"
      },
      "source": [
        "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pugapatricia/gestion-documentaria-para-pymes/blob/main/etiquetado/Generador_etiquetasHF.ipynb)\n",
        "\n",
        "[![Ver en GitHub](https://img.shields.io/badge/GitHub-Repo-black?logo=github)](https://github.com/pugapatricia/gestion-documentaria-para-pymes/tree/main/etiquetado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPOn6tibIKxm"
      },
      "source": [
        "#Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q_rAOUDjdz8D"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests msal python-docx PyPDF2 pandas openpyxl python-pptx openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fJ1Ko6i0cNaP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import msal\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from pptx import Presentation\n",
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "from openai import OpenAI\n",
        "import re\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0E-lCnBdT9w"
      },
      "source": [
        "# Configuraci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "USm2IuiscQIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06583770-6fd3-4f31-c3d7-c7ce0734b1b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "CLIENT_ID = \"e3f2393e-7348-47d1-9c64-8d8efe6a5e95\"\n",
        "AUTHORITY = \"https://login.microsoftonline.com/consumers\"\n",
        "SCOPE = [\"User.Read\", \"Files.ReadWrite\"]\n",
        "\n",
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"pptx\", \"txt\", \"csv\"}\n",
        "url = \"https://graph.microsoft.com/v1.0/me/drive/root:/Etiquetados:/children\"\n",
        "\n",
        "etiquetas_global = set()\n",
        "# device=0 usa la primera GPU, device=-1 fuerza CPU\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1uxqbv6eEsp"
      },
      "source": [
        "# Conecci√≥n con OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSR-s8KvbuPf",
        "outputId": "f86e4c77-fd07-40f5-a28f-1ceff66ec240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To sign in, use a web browser to open the page https://www.microsoft.com/link and enter the code PREP256R to authenticate.\n"
          ]
        }
      ],
      "source": [
        "app = msal.PublicClientApplication(CLIENT_ID, authority=AUTHORITY)\n",
        "\n",
        "flow = app.initiate_device_flow(scopes=SCOPE)\n",
        "if \"user_code\" not in flow:\n",
        "    raise Exception(\"No se pudo iniciar el device flow. Revisa tu configuraci√≥n en Azure.\")\n",
        "\n",
        "print(flow[\"message\"])  # üëâ Copia el c√≥digo en https://microsoft.com/devicelogin\n",
        "result = app.acquire_token_by_device_flow(flow)\n",
        "\n",
        "if \"access_token\" not in result:\n",
        "    raise Exception(f\"Error autenticaci√≥n: {result.get('error_description')}\")\n",
        "\n",
        "access_token = result[\"access_token\"]\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Llamada a la API con tu token de acceso\n",
        "resp = requests.get(url, headers=headers)\n",
        "if resp.status_code != 200:\n",
        "    raise Exception(f\"Error al obtener archivos: {resp.text}\")\n",
        "data = resp.json()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_nDVZvpeU4D"
      },
      "source": [
        "# Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-wlPBMaFlMo"
      },
      "source": [
        "Procesamos cada documento de acuerdo con su tipo (PDF, Word, Excel, etc.) para convertirlo en datos estructurados. Este proceso se realiza mediante las siguientes funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XbiD5bBaeTgS"
      },
      "outputs": [],
      "source": [
        "def leer_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "def leer_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "\n",
        "def leer_excel(file_path):\n",
        "    try:\n",
        "        df_dict = pd.read_excel(file_path, sheet_name=None)\n",
        "    except Exception as e:\n",
        "        return f\"Error leyendo Excel: {e}\"\n",
        "\n",
        "    texto = []\n",
        "    for nombre, hoja in df_dict.items():\n",
        "        hoja = hoja.fillna(\"\")  # reemplaza NaN por \"\"\n",
        "        texto.append(f\"\\n--- Hoja: {nombre} ---\\n\")\n",
        "        texto.append(hoja.to_string())\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df.to_string()\n",
        "\n",
        "def leer_pptx(file_path):\n",
        "    prs = Presentation(file_path)\n",
        "    texto = []\n",
        "    for i, slide in enumerate(prs.slides, 1):\n",
        "        texto.append(f\"\\n--- Diapositiva {i} ---\\n\")\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text_frame\") and shape.text_frame:\n",
        "                texto.append(shape.text_frame.text)\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_txt(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def procesar_archivo_temporal(item):\n",
        "    nombre = item.get(\"name\")\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext not in ext_permitidas:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3bq9a30FfQK"
      },
      "source": [
        "Funci√≥n para solicitar a OpenAI la generaci√≥n de etiquetas/tickers por documento, con un l√≠mite m√°ximo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gHqP9jJ3GFJI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sugerir_tickers(texto, max_etiquetas=10):\n",
        "    if not texto.strip():\n",
        "        return []\n",
        "\n",
        "    candidate_labels = texto.split()\n",
        "    resultado = classifier(texto, candidate_labels, multi_label=True)\n",
        "\n",
        "    etiquetas_lista = [word.lower() for word, score in zip(resultado['labels'], resultado['scores'])][:max_etiquetas]\n",
        "    etiquetas_global.update(etiquetas_lista)\n",
        "    return etiquetas_lista\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b55PVyzZGsXI"
      },
      "source": [
        "Descarga un archivo temporal desde una URL, verifica que su extensi√≥n est√© permitida y lo lee seg√∫n su tipo, devolviendo su contenido como texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-XvATayYGtgq"
      },
      "outputs": [],
      "source": [
        "def procesar_archivo_temporal(item):\n",
        "    nombre = item.get(\"name\")\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext not in ext_permitidas:\n",
        "        return \"\"\n",
        "\n",
        "    tmp_path = f\"/tmp/{nombre}\"\n",
        "    try:\n",
        "        r = requests.get(item[\"@microsoft.graph.downloadUrl\"], stream=True)\n",
        "        r.raise_for_status()\n",
        "        with open(tmp_path, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        if ext == \"pdf\":\n",
        "            return leer_pdf(tmp_path)\n",
        "        elif ext == \"docx\":\n",
        "            return leer_docx(tmp_path)\n",
        "        elif ext in {\"xlsx\", \"xls\"}:\n",
        "            return leer_excel(tmp_path)\n",
        "        elif ext == \"pptx\":\n",
        "            return leer_pptx(tmp_path)\n",
        "        elif ext == \"txt\":\n",
        "            return leer_txt(tmp_path)\n",
        "        elif ext == \"csv\":\n",
        "            return leer_csv(tmp_path)\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"‚ö†Ô∏è Error descargando {nombre}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error procesando {nombre}: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(tmp_path):\n",
        "            os.remove(tmp_path)\n",
        "\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmIJsSXerQS"
      },
      "source": [
        "# LISTAR Y PROCESAR ARCHIVOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t14O58CkepJq"
      },
      "outputs": [],
      "source": [
        "tickers_global = set()\n",
        "\n",
        "for idx, item in enumerate(data.get(\"value\", [])):\n",
        "    if idx >= 1 or \"folder\" in item:  # Solo procesa el primer documento\n",
        "        continue\n",
        "\n",
        "    texto = procesar_archivo_temporal(item)\n",
        "    if texto.strip():\n",
        "        try:\n",
        "            sugerencias = sugerir_tickers(texto, max_etiquetas=10)\n",
        "            tickers_global.update([s.strip() for s in sugerencias if s.strip()])\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error generando etiquetas para {item.get('name')}: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Tickers finales:\\n\", sorted(tickers_global))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}