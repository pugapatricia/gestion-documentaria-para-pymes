{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-KarOQNArIt"
      },
      "source": [
        "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pugapatricia/gestion-documentaria-para-pymes/blob/main/etiquetado/Generador_etiquetas.ipynb)\n",
        "\n",
        "[![Ver en GitHub](https://img.shields.io/badge/GitHub-Repo-black?logo=github)](https://github.com/pugapatricia/gestion-documentaria-para-pymes/tree/main/etiquetado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPOn6tibIKxm"
      },
      "source": [
        "#Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q_rAOUDjdz8D",
        "outputId": "20b68cfd-19da-4287-da2c-bbc1d44a43e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/117.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m112.6/117.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q requests msal python-docx PyPDF2 pandas openpyxl python-pptx openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fJ1Ko6i0cNaP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import msal\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from pptx import Presentation\n",
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0E-lCnBdT9w"
      },
      "source": [
        "# Configuraci贸n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = getpass.getpass(\"Introduce tu OpenAI API Key: \")\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "ukAIZ3q6q5zq",
        "outputId": "11eac251-29ba-4aff-98a5-9bc42437db55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduce tu OpenAI API Key: 路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "USm2IuiscQIt"
      },
      "outputs": [],
      "source": [
        "CLIENT_ID = \"e3f2393e-7348-47d1-9c64-8d8efe6a5e95\"\n",
        "AUTHORITY = \"https://login.microsoftonline.com/consumers\"\n",
        "SCOPE = [\"User.Read\", \"Files.ReadWrite\"]\n",
        "\n",
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"pptx\", \"txt\", \"csv\"}\n",
        "url = \"https://graph.microsoft.com/v1.0/me/drive/root:/Etiquetados:/children\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1uxqbv6eEsp"
      },
      "source": [
        "# Conecci贸n con OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSR-s8KvbuPf"
      },
      "outputs": [],
      "source": [
        "app = msal.PublicClientApplication(CLIENT_ID, authority=AUTHORITY)\n",
        "\n",
        "flow = app.initiate_device_flow(scopes=SCOPE)\n",
        "if \"user_code\" not in flow:\n",
        "    raise Exception(\"No se pudo iniciar el device flow. Revisa tu configuraci贸n en Azure.\")\n",
        "\n",
        "print(flow[\"message\"])  #  Copia el c贸digo en https://microsoft.com/devicelogin\n",
        "result = app.acquire_token_by_device_flow(flow)\n",
        "\n",
        "if \"access_token\" not in result:\n",
        "    raise Exception(f\"Error autenticaci贸n: {result.get('error_description')}\")\n",
        "\n",
        "access_token = result[\"access_token\"]\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Llamada a la API con tu token de acceso\n",
        "resp = requests.get(url, headers=headers)\n",
        "if resp.status_code != 200:\n",
        "    raise Exception(f\"Error al obtener archivos: {resp.text}\")\n",
        "data = resp.json()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_nDVZvpeU4D"
      },
      "source": [
        "# Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-wlPBMaFlMo"
      },
      "source": [
        "Procesamos cada documento de acuerdo con su tipo (PDF, Word, Excel, etc.) para convertirlo en datos estructurados. Este proceso se realiza mediante las siguientes funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbiD5bBaeTgS"
      },
      "outputs": [],
      "source": [
        "def leer_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "def leer_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "\n",
        "def leer_excel(file_path):\n",
        "    try:\n",
        "        df_dict = pd.read_excel(file_path, sheet_name=None)\n",
        "    except Exception as e:\n",
        "        return f\"Error leyendo Excel: {e}\"\n",
        "\n",
        "    texto = []\n",
        "    for nombre, hoja in df_dict.items():\n",
        "        hoja = hoja.fillna(\"\")  # reemplaza NaN por \"\"\n",
        "        texto.append(f\"\\n--- Hoja: {nombre} ---\\n\")\n",
        "        texto.append(hoja.to_string())\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df.to_string()\n",
        "\n",
        "def leer_pptx(file_path):\n",
        "    prs = Presentation(file_path)\n",
        "    texto = []\n",
        "    for i, slide in enumerate(prs.slides, 1):\n",
        "        texto.append(f\"\\n--- Diapositiva {i} ---\\n\")\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text_frame\") and shape.text_frame:\n",
        "                texto.append(shape.text_frame.text)\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_txt(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def procesar_archivo_temporal(item):\n",
        "    nombre = item.get(\"name\")\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext not in ext_permitidas:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3bq9a30FfQK"
      },
      "source": [
        "Funci贸n para solicitar a OpenAI la generaci贸n de etiquetas/tickers por documento, con un l铆mite m谩ximo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHqP9jJ3GFJI"
      },
      "outputs": [],
      "source": [
        "etiquetas_global = set()\n",
        "\n",
        "def sugerir_tickers(texto, max_etiquetas=10):\n",
        "    if not texto.strip():\n",
        "        return []\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Eres un asistente que recibe un texto de un documento.\n",
        "Devuelve solo las {max_etiquetas} palabras m谩s importantes\n",
        "que podr铆an usarse como etiquetas del documento, una sola palabra cada una,\n",
        "en una lista separada por comas. No agregues explicaciones, solo las palabras.\n",
        "\n",
        "Texto:\n",
        "{texto}\n",
        "\"\"\"\n",
        "    try:\n",
        "        respuesta = client.chat.completions.create(\n",
        "            model=\"gpt-5-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "\n",
        "        etiquetas = respuesta.choices[0].message.content\n",
        "        etiquetas_lista = [e.strip().lower() for e in re.split(r'[,\\n;]+', etiquetas) if e.strip()]\n",
        "        etiquetas_lista = list(dict.fromkeys(etiquetas_lista))[:max_etiquetas]\n",
        "        etiquetas_global.update(etiquetas_lista)\n",
        "\n",
        "        return etiquetas_lista\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"锔 Error al generar etiquetas: {e}\")\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b55PVyzZGsXI"
      },
      "source": [
        "Descarga un archivo temporal desde una URL, verifica que su extensi贸n est茅 permitida y lo lee seg煤n su tipo, devolviendo su contenido como texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XvATayYGtgq"
      },
      "outputs": [],
      "source": [
        "tickers_global = set()\n",
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"pptx\", \"txt\", \"csv\"}\n",
        "\n",
        "def procesar_archivo_temporal(item):\n",
        "    nombre = item.get(\"name\")\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext not in ext_permitidas:\n",
        "        return \"\"\n",
        "\n",
        "    tmp_path = f\"/tmp/{nombre}\"\n",
        "    try:\n",
        "        r = requests.get(item[\"@microsoft.graph.downloadUrl\"], stream=True)\n",
        "        r.raise_for_status()\n",
        "        with open(tmp_path, \"wb\") as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        if ext == \"pdf\":\n",
        "            return leer_pdf(tmp_path)\n",
        "        elif ext == \"docx\":\n",
        "            return leer_docx(tmp_path)\n",
        "        elif ext in {\"xlsx\", \"xls\"}:\n",
        "            return leer_excel(tmp_path)\n",
        "        elif ext == \"pptx\":\n",
        "            return leer_pptx(tmp_path)\n",
        "        elif ext == \"txt\":\n",
        "            return leer_txt(tmp_path)\n",
        "        elif ext == \"csv\":\n",
        "            return leer_csv(tmp_path)\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"锔 Error descargando {nombre}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"锔 Error procesando {nombre}: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(tmp_path):\n",
        "            os.remove(tmp_path)\n",
        "\n",
        "    return \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmIJsSXerQS"
      },
      "source": [
        "# LISTAR Y PROCESAR ARCHIVOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t14O58CkepJq"
      },
      "outputs": [],
      "source": [
        "# Procesar los primeros 5 archivos no folders\n",
        "for idx, item in enumerate(data.get(\"value\", [])):\n",
        "    if idx >= 5 or \"folder\" in item:\n",
        "        continue\n",
        "\n",
        "    texto = procesar_archivo_temporal(item)\n",
        "    if texto.strip():\n",
        "        # Obtener sugerencias de tickers (empresas)\n",
        "        try:\n",
        "            sugerencias = sugerir_tickers(texto, max_etiquetas=10)\n",
        "            tickers_global.update([s.strip() for s in sugerencias if s.strip()])\n",
        "        except Exception as e:\n",
        "            print(f\"锔 Error generando etiquetas para {item.get('name')}: {e}\")\n",
        "\n",
        "print(\"\\nTickers finales:\\n\", sorted(tickers_global))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}