{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-KarOQNArIt"
      },
      "source": [
        "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pugapatricia/gestion-documentaria-para-pymes/blob/main/etiquetado/UnionEtiquetado_open.ipynb)\n",
        "\n",
        "[![Ver en GitHub](https://img.shields.io/badge/GitHub-Repo-black?logo=github)](https://github.com/pugapatricia/gestion-documentaria-para-pymes/tree/main/etiquetado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPOn6tibIKxm"
      },
      "source": [
        "#Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "q_rAOUDjdz8D"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests msal python-docx PyPDF2 pandas openpyxl python-pptx openai unidecode xlrd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlrd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JNmVybVDPEf",
        "outputId": "3ee8f62c-b723-40c0-ce03-b5201ff6ff59"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fJ1Ko6i0cNaP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import msal\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from pptx import Presentation\n",
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import getpass\n",
        "import io, os, re, requests\n",
        "import pandas as pd\n",
        "import PyPDF2, openpyxl\n",
        "from pptx import Presentation\n",
        "from docx import Document\n",
        "import unidecode\n",
        "import openpyxl\n",
        "import xlrd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0E-lCnBdT9w"
      },
      "source": [
        "# Configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukAIZ3q6q5zq",
        "outputId": "b33b607f-9add-466e-f7ed-fab77a5d7934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduce tu OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "api_key = getpass.getpass(\"Introduce tu OpenAI API Key: \")\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "USm2IuiscQIt"
      },
      "outputs": [],
      "source": [
        "CLIENT_ID = \"e3f2393e-7348-47d1-9c64-8d8efe6a5e95\"\n",
        "AUTHORITY = \"https://login.microsoftonline.com/consumers\"\n",
        "SCOPE = [\"User.Read\", \"Files.ReadWrite.All\"]\n",
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"pptx\", \"txt\", \"csv\"}\n",
        "url = \"https://graph.microsoft.com/v1.0/me/drive/root:/Etiquetados:/children\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1uxqbv6eEsp"
      },
      "source": [
        "# Conección con OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fSR-s8KvbuPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fb5a3e-a124-40e7-f749-5330ed8423a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To sign in, use a web browser to open the page https://www.microsoft.com/link and enter the code AP3BQGDF to authenticate.\n"
          ]
        }
      ],
      "source": [
        "app = msal.PublicClientApplication(CLIENT_ID, authority=AUTHORITY)\n",
        "\n",
        "flow = app.initiate_device_flow(scopes=SCOPE)\n",
        "if \"user_code\" not in flow:\n",
        "    raise Exception(\"No se pudo iniciar el device flow. Revisa tu configuración en Azure.\")\n",
        "\n",
        "print(flow[\"message\"])  # 👉 Copia el código en https://microsoft.com/devicelogin\n",
        "result = app.acquire_token_by_device_flow(flow)\n",
        "\n",
        "if \"access_token\" not in result:\n",
        "    raise Exception(f\"Error autenticación: {result.get('error_description')}\")\n",
        "\n",
        "access_token = result[\"access_token\"]\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Llamada a la API con tu token de acceso\n",
        "resp = requests.get(url, headers=headers)\n",
        "if resp.status_code != 200:\n",
        "    raise Exception(f\"Error al obtener archivos: {resp.text}\")\n",
        "data = resp.json()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_nDVZvpeU4D"
      },
      "source": [
        "# Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-wlPBMaFlMo"
      },
      "source": [
        "Procesamos cada documento de acuerdo con su tipo (PDF, Word, Excel, etc.) para convertirlo en datos estructurados. Este proceso se realiza mediante las siguientes funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XbiD5bBaeTgS"
      },
      "outputs": [],
      "source": [
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"csv\", \"txt\", \"pptx\"}\n",
        "\n",
        "def leer_pdf(file_path_or_bytes):\n",
        "    text = \"\"\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        reader = PyPDF2.PdfReader(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        reader = PyPDF2.PdfReader(file_path_or_bytes)\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "def leer_docx(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        doc = Document(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        doc = Document(file_path_or_bytes)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "\n",
        "def leer_excel(file_path_or_bytes):\n",
        "    texto = []\n",
        "\n",
        "    # Detectar extensión si es archivo en disco\n",
        "    ext = None\n",
        "    if isinstance(file_path_or_bytes, str):\n",
        "        ext = file_path_or_bytes.split(\".\")[-1].lower()\n",
        "    elif isinstance(file_path_or_bytes, bytes):\n",
        "        # Por simplicidad asumimos .xlsx si no hay extensión\n",
        "        ext = \"xlsx\"\n",
        "\n",
        "    if ext == \"xls\":\n",
        "        # Usar xlrd para archivos antiguos\n",
        "        temp_file = \"temp.xls\"\n",
        "        with open(temp_file, \"wb\") as f:\n",
        "            if isinstance(file_path_or_bytes, bytes):\n",
        "                f.write(file_path_or_bytes)\n",
        "            else:\n",
        "                with open(file_path_or_bytes, \"rb\") as orig:\n",
        "                    f.write(orig.read())\n",
        "        wb = xlrd.open_workbook(temp_file)\n",
        "        for sheet in wb.sheets():\n",
        "            texto.append(f\"\\n--- Hoja: {sheet.name} ---\\n\")\n",
        "            for row_idx in range(sheet.nrows):\n",
        "                row = sheet.row_values(row_idx)\n",
        "                row_text = \" \".join([str(c) for c in row if c])\n",
        "                if row_text.strip():\n",
        "                    texto.append(row_text)\n",
        "        os.remove(temp_file)\n",
        "\n",
        "    else:\n",
        "        # Usar openpyxl para .xlsx\n",
        "        if isinstance(file_path_or_bytes, bytes):\n",
        "            wb = openpyxl.load_workbook(io.BytesIO(file_path_or_bytes), data_only=True, read_only=True)\n",
        "        else:\n",
        "            wb = openpyxl.load_workbook(file_path_or_bytes, data_only=True, read_only=True)\n",
        "        for sheet in wb.worksheets:\n",
        "            texto.append(f\"\\n--- Hoja: {sheet.title} ---\\n\")\n",
        "            for row in sheet.iter_rows(values_only=True):\n",
        "                row_text = \" \".join([str(c) for c in row if c is not None])\n",
        "                if row_text.strip():\n",
        "                    texto.append(row_text)\n",
        "\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_csv(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        df = pd.read_csv(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        df = pd.read_csv(file_path_or_bytes)\n",
        "    return df.to_string()\n",
        "\n",
        "def leer_txt(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        return file_path_or_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "    with open(file_path_or_bytes, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def leer_pptx(file_path_or_bytes):\n",
        "    texto = []\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        prs = Presentation(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        prs = Presentation(file_path_or_bytes)\n",
        "    for i, slide in enumerate(prs.slides, 1):\n",
        "        texto.append(f\"\\n--- Diapositiva {i} ---\\n\")\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\") and shape.text.strip():\n",
        "                texto.append(shape.text)\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_archivo(item):\n",
        "    nombre = item.get(\"name\")\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext not in ext_permitidas:\n",
        "        return \"\"\n",
        "\n",
        "    tmp_path = f\"/tmp/{nombre}\"\n",
        "    try:\n",
        "        # Descargar archivo si no tenemos los bytes\n",
        "        if \"contenido\" in item:\n",
        "            contenido = item[\"contenido\"]\n",
        "            if isinstance(contenido, bytes):\n",
        "                with open(tmp_path, \"wb\") as f:\n",
        "                    f.write(contenido)\n",
        "        else:\n",
        "            r = requests.get(item[\"@microsoft.graph.downloadUrl\"], stream=True)\n",
        "            r.raise_for_status()\n",
        "            with open(tmp_path, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "        # Leer según extensión\n",
        "        if ext == \"pdf\":\n",
        "            return leer_pdf(tmp_path)\n",
        "        elif ext == \"docx\":\n",
        "            return leer_docx(tmp_path)\n",
        "        elif ext in {\"xlsx\", \"xls\"}:\n",
        "            return leer_excel(tmp_path)\n",
        "        elif ext == \"pptx\":\n",
        "            return leer_pptx(tmp_path)\n",
        "        elif ext == \"txt\":\n",
        "            return leer_txt(tmp_path)\n",
        "        elif ext == \"csv\":\n",
        "            return leer_csv(tmp_path)\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error descargando {nombre}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando {nombre}: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(tmp_path):\n",
        "            os.remove(tmp_path)\n",
        "\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3bq9a30FfQK"
      },
      "source": [
        "Función para solicitar a OpenAI la generación de etiquetas/tickers por documento, con un límite máximo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gHqP9jJ3GFJI"
      },
      "outputs": [],
      "source": [
        "etiquetas_global = set()\n",
        "\n",
        "def sugerir_tickers(texto, max_etiquetas=10):\n",
        "    if not texto.strip():\n",
        "        return []\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Eres un asistente que recibe un texto de un documento.\n",
        "Devuelve solo las {max_etiquetas} palabras más importantes\n",
        "que podrían usarse como etiquetas del documento, una sola palabra cada una,\n",
        "en una lista separada por comas. No agregues explicaciones, solo las palabras.\n",
        "\n",
        "Texto:\n",
        "{texto}\n",
        "\"\"\"\n",
        "    try:\n",
        "        respuesta = client.chat.completions.create(\n",
        "            model=\"gpt-5-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "\n",
        "        etiquetas = respuesta.choices[0].message.content\n",
        "        etiquetas_lista = [e.strip().lower() for e in re.split(r'[,\\n;]+', etiquetas) if e.strip()]\n",
        "        etiquetas_lista = list(dict.fromkeys(etiquetas_lista))[:max_etiquetas]\n",
        "        etiquetas_global.update(etiquetas_lista)\n",
        "\n",
        "        return etiquetas_lista\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error al generar etiquetas: {e}\")\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b55PVyzZGsXI"
      },
      "source": [
        "Descarga un archivo temporal desde una URL, verifica que su extensión esté permitida y lo lee según su tipo, devolviendo su contenido como texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmIJsSXerQS"
      },
      "source": [
        "# LISTAR Y PROCESAR ARCHIVOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "t14O58CkepJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f9e5e4-c9fd-47c7-9f39-7c7a74fb4b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tickers finales:\n",
            " ['actividad', 'activos', 'acuerdo', 'administrador', 'admitidos', 'agreement', 'agua', 'amortización', 'análisis', 'apalancamiento', 'archivo', 'arganda', 'arrendador', 'arrendamiento', 'arrendatario', 'arte', 'astrofísica', 'autorizacion', 'autorización', 'ayuntamiento', 'bachillerato', 'balance', 'breach', 'businessanalytics', 'capacitación', 'cauca', 'cervantes', 'cienciassociales', 'cláusulas', 'comparación', 'complutense', 'confidencialidad', 'confidentiality', 'consorcio', 'contabilidad', 'contrato', 'costos', 'crédito', 'curso', 'cursos', 'data', 'datascience', 'decisiones', 'demanda', 'derechos', 'desahucio', 'desalojo', 'disclosing', 'disclosure', 'divulgación', 'divulgador', 'documentación', 'duración', 'egresos', 'empaques', 'empresa', 'endeudamiento', 'estados', 'estancia', 'estrategias', 'estudiante', 'estudiantes', 'estudios', 'eva', 'excepciones', 'extranjero', 'extranjería', 'fianza', 'financiera', 'financiero', 'financieros', 'finca', 'flujo', 'flujodecaja', 'fuentes', 'ganadero', 'geografía', 'governing', 'habitación', 'historia', 'humanidades', 'idiomas', 'indemnización', 'indicadores', 'información', 'information', 'ingresos', 'inmueble', 'inquilino', 'interpretación', 'interés', 'inventarios', 'jarama', 'jurisdicción', 'lau', 'law', 'liquidez', 'madrid', 'marco', 'master', 'matemáticas', 'materias', 'matrícula', 'mediación', 'medioambiente', 'mendieta', 'modalidad', 'morosidad', 'motín', 'máster', 'métodos', 'nda', 'nie', 'notificaciones', 'obligaciones', 'optativa', 'panama', 'partes', 'pasaporte', 'pasivos', 'patrimonio', 'plantación', 'plazas', 'plazo', 'poesía', 'propiedad', 'propiedadintelectual', 'propietario', 'prorroga', 'proyección', 'proyecto', 'prórroga', 'puente', 'receiving', 'receptor', 'registro', 'regresión', 'renta', 'rentabilidad', 'rescisión', 'reserva', 'reservante', 'resolución', 'rústica', 'seguridad', 'seguro', 'señal', 'silvopastoril', 'solicitud', 'subarriendo', 'suministros', 'tasa', 'tauromaquia', 'temporada', 'term', 'tir', 'transporte', 'universidad', 'valoración', 'van', 'vigilancia', 'visado', 'vivienda']\n"
          ]
        }
      ],
      "source": [
        "etiquetas = set()  # convertir a set\n",
        "\n",
        "for item in data.get(\"value\", []):\n",
        "    if \"folder\" in item:\n",
        "        continue\n",
        "\n",
        "    texto = leer_archivo(item)\n",
        "    if texto.strip():\n",
        "        try:\n",
        "            sugerencias = sugerir_tickers(texto, max_etiquetas=10)\n",
        "            etiquetas.update([s.strip() for s in sugerencias if s.strip()])\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error generando etiquetas para {item.get('name')}: {e}\")\n",
        "\n",
        "print(\"\\nTickers finales:\\n\", sorted(etiquetas))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "etiquetas = list(etiquetas)"
      ],
      "metadata": {
        "id": "qDhpsRwPqTjO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(etiquetas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGAfz5tD3ZkS",
        "outputId": "037789bc-4c2d-46b0-d9f5-874958d388d0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ETIQUETADO"
      ],
      "metadata": {
        "id": "vUscjPpKWjnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_texto(texto: str) -> str:\n",
        "    if not texto:\n",
        "        return \"\"\n",
        "    texto = re.sub(r'\\d+\\n', '', texto)\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "    texto = re.sub(r'[^a-zA-Záéíóúüñ0-9\\s,.\\-()/:]', '', texto)\n",
        "    return texto.strip()\n",
        "\n",
        "def etiquetar_texto(texto, etiquetas, max_etiquetas=5, modelo=\"gpt-5-mini\"):\n",
        "    etiquetas_norm = {unidecode.unidecode(e.lower().replace(\" \", \"\")): e for e in etiquetas}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Analiza cuidadosamente el siguiente texto y selecciona hasta {max_etiquetas} etiquetas que mejor representen sus temas principales.\n",
        "Usa únicamente las etiquetas de la lista exacta que se proporciona más abajo, no inventes ninguna etiqueta.\n",
        "Lista de etiquetas: {', '.join(etiquetas)}\n",
        "\n",
        "Texto: \\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
        "\n",
        "Devuelve únicamente las etiquetas seleccionadas, separadas por comas, sin explicaciones ni palabras adicionales.\n",
        "Responde de forma precisa, considerando todo el contenido del texto.\n",
        "\"\"\"\n",
        "\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=400\n",
        "    )\n",
        "\n",
        "    raw = re.split(r'[,\\n;]+', respuesta.choices[0].message.content)\n",
        "    resultado = []\n",
        "    for e in raw:\n",
        "        key = unidecode.unidecode(e.strip().lower().replace(\" \", \"\"))\n",
        "        if key in etiquetas_norm:\n",
        "            resultado.append(etiquetas_norm[key])\n",
        "        elif key.endswith(\"s\") and key[:-1] in etiquetas_norm:\n",
        "            resultado.append(etiquetas_norm[key[:-1]])\n",
        "\n",
        "    return resultado[:max_etiquetas]"
      ],
      "metadata": {
        "id": "L9LDb_HAVg58"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"El contrato de arrendamiento establece claramente la renta, el plazo, las obligaciones del arrendador y arrendatario,\n",
        "y las cláusulas de prórroga y fianza. Además, se menciona la propiedad intelectual relacionada con los proyectos\n",
        "de divulgación científica, literatura y poesía, incluyendo derechos de autor y acuerdos de confidencialidad (NDA).\n",
        "El inmueble objeto del contrato deberá cumplir con las leyes y la jurisdicción aplicable, respetando las normas de\n",
        "financiación y las resoluciones de los organismos competentes. También se contemplan actividades culturales\n",
        "como teatro y arte, así como cursos monográficos de astrofísica y biodiversidad.\n",
        "\"\"\"\n",
        "texto_limpio = limpiar_texto(texto)\n",
        "\n",
        "resultado = etiquetar_texto(texto_limpio, etiquetas)\n",
        "print(\"Etiquetas detectadas:\", resultado)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I26kTKP5wS2B",
        "outputId": "c7ed35ab-6462-4c8a-cfa6-041367321b71"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas detectadas: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "archivos_permitidos = [\n",
        "    item for item in data.get(\"value\", [])\n",
        "    if \"folder\" not in item and item[\"name\"].split(\".\")[-1].lower() in ext_permitidas\n",
        "]\n",
        "\n",
        "archivos_a_procesar = archivos_permitidos[:3]\n",
        "\n",
        "if archivos_a_procesar:\n",
        "    resultados = {}\n",
        "\n",
        "    for item in archivos_a_procesar:\n",
        "        nombre = item[\"name\"]\n",
        "        download_url = item[\"@microsoft.graph.downloadUrl\"]\n",
        "\n",
        "        print(f\"Procesando archivo: {nombre}\")\n",
        "\n",
        "        file_bytes = requests.get(download_url).content\n",
        "        texto = leer_archivo(item)\n",
        "        texto = limpiar_texto(texto)\n",
        "\n",
        "        if texto:\n",
        "            etiquetas_detectadas = etiquetar_texto(texto,etiquetas)\n",
        "        else:\n",
        "            etiquetas_detectadas = []\n",
        "\n",
        "        resultados[nombre] = etiquetas_detectadas\n",
        "        print(f\"{nombre} → {etiquetas_detectadas}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-UdACXhq7Y",
        "outputId": "65efb322-9f30-4ad2-e684-65f7011360a9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando archivo: 11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf\n",
            "Error descargando 11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf: 401 Client Error: Unauthorized for url: https://my.microsoftpersonalcontent.com/personal/9f68595d59f0b70b/_layouts/15/download.aspx?UniqueId=c1bb0c8d-9040-4e3f-8ae9-2438b23c4747&Translate=false&tempauth=v1e.eyJzaXRlaWQiOiJjMjFhZmM2OC0xNDUxLTQyODEtOTNjYy0yOGZhNDQ4M2Y4YmIiLCJhcHBfZGlzcGxheW5hbWUiOiJFdGlxdWV0YXMiLCJhcHBpZCI6ImUzZjIzOTNlLTczNDgtNDdkMS05YzY0LThkOGVmZTZhNWU5NSIsImF1ZCI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMC9teS5taWNyb3NvZnRwZXJzb25hbGNvbnRlbnQuY29tQDkxODgwNDBkLTZjNjctNGM1Yi1iMTEyLTM2YTMwNGI2NmRhZCIsImV4cCI6IjE3NjExMjQxNzEifQ.783JUAbVwaYTW_JovwODPwnU7c7UAzlEEOLMo6bJgKuUkw2L14N8plNvxLuzOVkJXFpV8OWXJmquzv6qyB0xpyBURORQ0Ih4MCetvAv7tDrsBrMeX_g1uwGhhgvhvDkRVRp1TjoMhC1VfJgIz64uq-vkORoxE6W0ahMu3nEIqbi78MAwr_ZcT6aK2QXJSSdGlNTAO_Vu8lY_uVBtU_eSzCpmZ7US0hQk4KMcN8UeYJfDHVSjs3kQsczaC3lp0KA2GOXJbRmngW4PzD3BKzPV2wDwBjV3SLOwA80jVa1XTDfbnlRZ5uROhzo4QDRb2ybFDiJ53ih49LesliY3zr_uwkhvqDJpFfYVivrsFp6-xiXhImJq0FG3j0PruHmZ9ggEe5kmSNmij9C2e_gEF-zlrUEefKkw5BC3SHtku0cJmDAAf5fROql-BpgytraQX2BMxXs9bdcVXY7Pr9vcMuwL9A.oyLVXwj-X2w4-JQ3qMsRV8q8Mai55gN7rMweTrpUv34&ApiVersion=2.0\n",
            "11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf → []\n",
            "Procesando archivo: 2016-admitidos_Segundo ciclo- Cursos monográficos.xls\n",
            "Error descargando 2016-admitidos_Segundo ciclo- Cursos monográficos.xls: 401 Client Error: Unauthorized for url: https://my.microsoftpersonalcontent.com/personal/9f68595d59f0b70b/_layouts/15/download.aspx?UniqueId=78aae573-4f90-4067-84d2-5ad06797bcc6&Translate=false&tempauth=v1e.eyJzaXRlaWQiOiJjMjFhZmM2OC0xNDUxLTQyODEtOTNjYy0yOGZhNDQ4M2Y4YmIiLCJhcHBfZGlzcGxheW5hbWUiOiJFdGlxdWV0YXMiLCJhcHBpZCI6ImUzZjIzOTNlLTczNDgtNDdkMS05YzY0LThkOGVmZTZhNWU5NSIsImF1ZCI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMC9teS5taWNyb3NvZnRwZXJzb25hbGNvbnRlbnQuY29tQDkxODgwNDBkLTZjNjctNGM1Yi1iMTEyLTM2YTMwNGI2NmRhZCIsImV4cCI6IjE3NjExMjQxNzEifQ.kP4KEsOZyf0zoty97oKQI14807mLGDodWqHsoob9gjw2XQydJ4upi-ij35HyXSld9NyKLCLvIP9r7j1uEbyG2qZHH6GHx-8sxefPMfxOmHSb_1lw6lnWiIli72CZJ3xHvEFbltFwpGZR8CATrIb0x7iqXTeEBpvLacy7P9wdmzZucw5H9mvKr5g4eVixFKUcwyPtFgWzkMYu8bG2MR3S9uTboqFMdRIxuV2uzqH5WxwiOH6V6JRyskBVfpfrffWeMFcj6DQY8tSLIt8gN5boigQV5KcSXTsyxr_h5Uvq0jreN8Fv-st8DoumvBe9tg_yOM6N3bg6dJEysQh-cbzh1x56edSVYFugQhkrHr2Sv7_k1cZg31RP5Q8311plZPhGISiM9TAaJbpGynul48wPuDNLZIwzvfnoUUyW6CGtjfKYOlJF1WPQ6ZvPmjnsjiXPLuf21a6Q0ZSPJBrBOKcPUg.ey_AHbkLQq_qh65mBcLcuoOyZii_Xqz0dq-ZLjEQ_dM&ApiVersion=2.0\n",
            "2016-admitidos_Segundo ciclo- Cursos monográficos.xls → []\n",
            "Procesando archivo: 2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx\n",
            "Error descargando 2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx: 401 Client Error: Unauthorized for url: https://my.microsoftpersonalcontent.com/personal/9f68595d59f0b70b/_layouts/15/download.aspx?UniqueId=c776b69a-0375-4771-b022-1ba01443bd62&Translate=false&tempauth=v1e.eyJzaXRlaWQiOiJjMjFhZmM2OC0xNDUxLTQyODEtOTNjYy0yOGZhNDQ4M2Y4YmIiLCJhcHBfZGlzcGxheW5hbWUiOiJFdGlxdWV0YXMiLCJhcHBpZCI6ImUzZjIzOTNlLTczNDgtNDdkMS05YzY0LThkOGVmZTZhNWU5NSIsImF1ZCI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMC9teS5taWNyb3NvZnRwZXJzb25hbGNvbnRlbnQuY29tQDkxODgwNDBkLTZjNjctNGM1Yi1iMTEyLTM2YTMwNGI2NmRhZCIsImV4cCI6IjE3NjExMjQxNzEifQ.kLy31FAFIke5MVYqtfrS9_GyYXfTJhH34IqBKdPtCMDEILqVd4TBTyecZmZlx_EULremvJsGg84-_YHjMUxQwJmReVVpOJVWDlHfQF4tq3lVU_LdKJ8BzgQAEnPMYS0K2lCXfA7_SULgOMJi9C4ZT0DTC_Cc4Yw9L5yqtnjsufe-gKBluBtYCSCky4qhk4RrRCVCB0uuUNKedzXS8vOczi6UJ-WBmauaq9xzNPuf4082CmcOIo5Son45gzxP56EBsPzqYkLeqGaQUrzymZuYx46ao1p3XUcgPT8iPE1K1U6Z94gHRYIuFh_i-f6WOZ-t2CzYvppVev9BlB9_NusYHADVg-U5x0RltmjK2sS7zoOf4F7f77L75Fyhg6xc_4faN2PB1OwsobKQIP_-s24ZD4kJeRvIjS96cXSW57d32KLX1jxtjcIr2YhfmjJOWwKP7uWurTFHeD_yUi7nvlyoQg.y7z3J9W33vdQurwTPr1RICEfrJvIjwD_270l7enVIVk&ApiVersion=2.0\n",
            "2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx → []\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}