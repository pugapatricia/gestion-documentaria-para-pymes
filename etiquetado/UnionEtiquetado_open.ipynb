{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-KarOQNArIt"
      },
      "source": [
        "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pugapatricia/gestion-documentaria-para-pymes/blob/main/etiquetado/UnionEtiquetado_open.ipynb)\n",
        "\n",
        "[![Ver en GitHub](https://img.shields.io/badge/GitHub-Repo-black?logo=github)](https://github.com/pugapatricia/gestion-documentaria-para-pymes/tree/main/etiquetado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPOn6tibIKxm"
      },
      "source": [
        "#Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_rAOUDjdz8D",
        "outputId": "87979996-24bd-4d32-8bf8-6b8de3d6262f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/235.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m235.5/235.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q requests msal python-docx PyPDF2 pandas openpyxl python-pptx openai unidecode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "fJ1Ko6i0cNaP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import msal\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from pptx import Presentation\n",
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import getpass\n",
        "import io, os, re, requests\n",
        "import pandas as pd\n",
        "import PyPDF2, openpyxl\n",
        "from pptx import Presentation\n",
        "from docx import Document\n",
        "import unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0E-lCnBdT9w"
      },
      "source": [
        "# Configuraci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukAIZ3q6q5zq",
        "outputId": "577931f1-3309-4bff-f53f-0618b7814d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduce tu OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "api_key = getpass.getpass(\"Introduce tu OpenAI API Key: \")\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "USm2IuiscQIt"
      },
      "outputs": [],
      "source": [
        "CLIENT_ID = \"e3f2393e-7348-47d1-9c64-8d8efe6a5e95\"\n",
        "AUTHORITY = \"https://login.microsoftonline.com/consumers\"\n",
        "SCOPE = [\"User.Read\", \"Files.ReadWrite.All\"]\n",
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"pptx\", \"txt\", \"csv\"}\n",
        "url = \"https://graph.microsoft.com/v1.0/me/drive/root:/Etiquetados:/children\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1uxqbv6eEsp"
      },
      "source": [
        "# Conecci√≥n con OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "fSR-s8KvbuPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9309068e-e632-4d1b-bb7f-6271f74a899a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To sign in, use a web browser to open the page https://www.microsoft.com/link and enter the code T2KWS8HE to authenticate.\n"
          ]
        }
      ],
      "source": [
        "app = msal.PublicClientApplication(CLIENT_ID, authority=AUTHORITY)\n",
        "\n",
        "flow = app.initiate_device_flow(scopes=SCOPE)\n",
        "if \"user_code\" not in flow:\n",
        "    raise Exception(\"No se pudo iniciar el device flow. Revisa tu configuraci√≥n en Azure.\")\n",
        "\n",
        "print(flow[\"message\"])  # üëâ Copia el c√≥digo en https://microsoft.com/devicelogin\n",
        "result = app.acquire_token_by_device_flow(flow)\n",
        "\n",
        "if \"access_token\" not in result:\n",
        "    raise Exception(f\"Error autenticaci√≥n: {result.get('error_description')}\")\n",
        "\n",
        "access_token = result[\"access_token\"]\n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "\n",
        "# Llamada a la API con tu token de acceso\n",
        "resp = requests.get(url, headers=headers)\n",
        "if resp.status_code != 200:\n",
        "    raise Exception(f\"Error al obtener archivos: {resp.text}\")\n",
        "data = resp.json()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_nDVZvpeU4D"
      },
      "source": [
        "# Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-wlPBMaFlMo"
      },
      "source": [
        "Procesamos cada documento de acuerdo con su tipo (PDF, Word, Excel, etc.) para convertirlo en datos estructurados. Este proceso se realiza mediante las siguientes funciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "XbiD5bBaeTgS"
      },
      "outputs": [],
      "source": [
        "ext_permitidas = {\"pdf\", \"docx\", \"xlsx\", \"xls\", \"csv\", \"txt\", \"pptx\"}\n",
        "\n",
        "def leer_pdf(file_path_or_bytes):\n",
        "    text = \"\"\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        reader = PyPDF2.PdfReader(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        reader = PyPDF2.PdfReader(file_path_or_bytes)\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() or \"\"\n",
        "    return text\n",
        "\n",
        "def leer_docx(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        doc = Document(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        doc = Document(file_path_or_bytes)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs])\n",
        "\n",
        "def leer_excel(file_path_or_bytes):\n",
        "    texto = []\n",
        "\n",
        "    # Detectar extensi√≥n si es archivo en disco\n",
        "    ext = None\n",
        "    if isinstance(file_path_or_bytes, str):\n",
        "        ext = file_path_or_bytes.split(\".\")[-1].lower()\n",
        "    elif isinstance(file_path_or_bytes, bytes):\n",
        "        # Por simplicidad asumimos .xlsx si no hay extensi√≥n\n",
        "        ext = \"xlsx\"\n",
        "\n",
        "    if ext == \"xls\":\n",
        "        # Usar xlrd para archivos antiguos\n",
        "        temp_file = \"temp.xls\"\n",
        "        with open(temp_file, \"wb\") as f:\n",
        "            if isinstance(file_path_or_bytes, bytes):\n",
        "                f.write(file_path_or_bytes)\n",
        "            else:\n",
        "                with open(file_path_or_bytes, \"rb\") as orig:\n",
        "                    f.write(orig.read())\n",
        "        wb = xlrd.open_workbook(temp_file)\n",
        "        for sheet in wb.sheets():\n",
        "            texto.append(f\"\\n--- Hoja: {sheet.name} ---\\n\")\n",
        "            for row_idx in range(sheet.nrows):\n",
        "                row = sheet.row_values(row_idx)\n",
        "                row_text = \" \".join([str(c) for c in row if c])\n",
        "                if row_text.strip():\n",
        "                    texto.append(row_text)\n",
        "        os.remove(temp_file)\n",
        "\n",
        "    else:\n",
        "        # Usar openpyxl para .xlsx\n",
        "        if isinstance(file_path_or_bytes, bytes):\n",
        "            wb = openpyxl.load_workbook(io.BytesIO(file_path_or_bytes), data_only=True, read_only=True)\n",
        "        else:\n",
        "            wb = openpyxl.load_workbook(file_path_or_bytes, data_only=True, read_only=True)\n",
        "        for sheet in wb.worksheets:\n",
        "            texto.append(f\"\\n--- Hoja: {sheet.title} ---\\n\")\n",
        "            for row in sheet.iter_rows(values_only=True):\n",
        "                row_text = \" \".join([str(c) for c in row if c is not None])\n",
        "                if row_text.strip():\n",
        "                    texto.append(row_text)\n",
        "\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_csv(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        df = pd.read_csv(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        df = pd.read_csv(file_path_or_bytes)\n",
        "    return df.to_string()\n",
        "\n",
        "def leer_txt(file_path_or_bytes):\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        return file_path_or_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "    with open(file_path_or_bytes, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def leer_pptx(file_path_or_bytes):\n",
        "    texto = []\n",
        "    if isinstance(file_path_or_bytes, bytes):\n",
        "        prs = Presentation(io.BytesIO(file_path_or_bytes))\n",
        "    else:\n",
        "        prs = Presentation(file_path_or_bytes)\n",
        "    for i, slide in enumerate(prs.slides, 1):\n",
        "        texto.append(f\"\\n--- Diapositiva {i} ---\\n\")\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\") and shape.text.strip():\n",
        "                texto.append(shape.text)\n",
        "    return \"\\n\".join(texto)\n",
        "\n",
        "def leer_archivo(item):\n",
        "    nombre = item.get(\"name\")\n",
        "    ext = nombre.split(\".\")[-1].lower()\n",
        "    if ext not in ext_permitidas:\n",
        "        return \"\"\n",
        "\n",
        "    tmp_path = f\"/tmp/{nombre}\"\n",
        "    try:\n",
        "        # Descargar archivo si no tenemos los bytes\n",
        "        if \"contenido\" in item:\n",
        "            contenido = item[\"contenido\"]\n",
        "            if isinstance(contenido, bytes):\n",
        "                with open(tmp_path, \"wb\") as f:\n",
        "                    f.write(contenido)\n",
        "        else:\n",
        "            r = requests.get(item[\"@microsoft.graph.downloadUrl\"], stream=True)\n",
        "            r.raise_for_status()\n",
        "            with open(tmp_path, \"wb\") as f:\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "        # Leer seg√∫n extensi√≥n\n",
        "        if ext == \"pdf\":\n",
        "            return leer_pdf(tmp_path)\n",
        "        elif ext == \"docx\":\n",
        "            return leer_docx(tmp_path)\n",
        "        elif ext in {\"xlsx\", \"xls\"}:\n",
        "            return leer_excel(tmp_path)\n",
        "        elif ext == \"pptx\":\n",
        "            return leer_pptx(tmp_path)\n",
        "        elif ext == \"txt\":\n",
        "            return leer_txt(tmp_path)\n",
        "        elif ext == \"csv\":\n",
        "            return leer_csv(tmp_path)\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error descargando {nombre}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando {nombre}: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(tmp_path):\n",
        "            os.remove(tmp_path)\n",
        "\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3bq9a30FfQK"
      },
      "source": [
        "Funci√≥n para solicitar a OpenAI la generaci√≥n de etiquetas/tickers por documento, con un l√≠mite m√°ximo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "gHqP9jJ3GFJI"
      },
      "outputs": [],
      "source": [
        "etiquetas_global = set()\n",
        "\n",
        "def sugerir_tickers(texto, max_etiquetas=10):\n",
        "    if not texto.strip():\n",
        "        return []\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Eres un asistente que recibe un texto de un documento.\n",
        "Devuelve solo las {max_etiquetas} palabras m√°s importantes\n",
        "que podr√≠an usarse como etiquetas del documento, una sola palabra cada una,\n",
        "en una lista separada por comas. No agregues explicaciones, solo las palabras.\n",
        "\n",
        "Texto:\n",
        "{texto}\n",
        "\"\"\"\n",
        "    try:\n",
        "        respuesta = client.chat.completions.create(\n",
        "            model=\"gpt-5-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "\n",
        "        etiquetas = respuesta.choices[0].message.content\n",
        "        etiquetas_lista = [e.strip().lower() for e in re.split(r'[,\\n;]+', etiquetas) if e.strip()]\n",
        "        etiquetas_lista = list(dict.fromkeys(etiquetas_lista))[:max_etiquetas]\n",
        "        etiquetas_global.update(etiquetas_lista)\n",
        "\n",
        "        return etiquetas_lista\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al generar etiquetas: {e}\")\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b55PVyzZGsXI"
      },
      "source": [
        "Descarga un archivo temporal desde una URL, verifica que su extensi√≥n est√© permitida y lo lee seg√∫n su tipo, devolviendo su contenido como texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmIJsSXerQS"
      },
      "source": [
        "# LISTAR Y PROCESAR ARCHIVOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t14O58CkepJq"
      },
      "outputs": [],
      "source": [
        "etiquetas = set()  # convertir a set\n",
        "\n",
        "for item in data.get(\"value\", []):\n",
        "    if \"folder\" in item:\n",
        "        continue\n",
        "\n",
        "    texto = leer_archivo(item)\n",
        "    if texto.strip():\n",
        "        try:\n",
        "            sugerencias = sugerir_tickers(texto, max_etiquetas=10)\n",
        "            etiquetas.update([s.strip() for s in sugerencias if s.strip()])\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error generando etiquetas para {item.get('name')}: {e}\")\n",
        "\n",
        "print(\"\\nTickers finales:\\n\", sorted(etiquetas))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "etiquetas = list(etiquetas)\n",
        "etiquetas"
      ],
      "metadata": {
        "id": "qDhpsRwPqTjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(etiquetas)"
      ],
      "metadata": {
        "id": "aGAfz5tD3ZkS",
        "outputId": "7bd8af07-77db-4e08-9865-8fa8cf30af7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ETIQUETADO"
      ],
      "metadata": {
        "id": "vUscjPpKWjnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_texto(texto: str) -> str:\n",
        "    if not texto:\n",
        "        return \"\"\n",
        "    texto = re.sub(r'\\d+\\n', '', texto)\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "    texto = re.sub(r'[^a-zA-Z√°√©√≠√≥√∫√º√±0-9\\s,.\\-()/:]', '', texto)\n",
        "    return texto.strip()\n",
        "\n",
        "def etiquetar_texto(texto, etiquetas, max_etiquetas=5, modelo=\"gpt-5-mini\"):\n",
        "    etiquetas_norm = {unidecode.unidecode(e.lower().replace(\" \", \"\")): e for e in etiquetas}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Analiza cuidadosamente el siguiente texto y selecciona hasta {max_etiquetas} etiquetas que mejor representen sus temas principales.\n",
        "Usa √∫nicamente las etiquetas de la lista exacta que se proporciona m√°s abajo, no inventes ninguna etiqueta.\n",
        "Lista de etiquetas: {', '.join(etiquetas)}\n",
        "\n",
        "Texto: \\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
        "\n",
        "Devuelve √∫nicamente las etiquetas seleccionadas, separadas por comas, sin explicaciones ni palabras adicionales.\n",
        "Responde de forma precisa, considerando todo el contenido del texto.\n",
        "\"\"\"\n",
        "\n",
        "    respuesta = client.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=400\n",
        "    )\n",
        "\n",
        "    raw = re.split(r'[,\\n;]+', respuesta.choices[0].message.content)\n",
        "    resultado = []\n",
        "    for e in raw:\n",
        "        key = unidecode.unidecode(e.strip().lower().replace(\" \", \"\"))\n",
        "        if key in etiquetas_norm:\n",
        "            resultado.append(etiquetas_norm[key])\n",
        "        elif key.endswith(\"s\") and key[:-1] in etiquetas_norm:\n",
        "            resultado.append(etiquetas_norm[key[:-1]])\n",
        "\n",
        "    return resultado[:max_etiquetas]"
      ],
      "metadata": {
        "id": "L9LDb_HAVg58"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"El contrato de arrendamiento establece claramente la renta, el plazo, las obligaciones del arrendador y arrendatario,\n",
        "y las cl√°usulas de pr√≥rroga y fianza. Adem√°s, se menciona la propiedad intelectual relacionada con los proyectos\n",
        "de divulgaci√≥n cient√≠fica, literatura y poes√≠a, incluyendo derechos de autor y acuerdos de confidencialidad (NDA).\n",
        "El inmueble objeto del contrato deber√° cumplir con las leyes y la jurisdicci√≥n aplicable, respetando las normas de\n",
        "financiaci√≥n y las resoluciones de los organismos competentes. Tambi√©n se contemplan actividades culturales\n",
        "como teatro y arte, as√≠ como cursos monogr√°ficos de astrof√≠sica y biodiversidad.\n",
        "\"\"\"\n",
        "texto_limpio = limpiar_texto(texto)\n",
        "\n",
        "resultado = etiquetar_texto(texto_limpio, etiquetas, max_etiquetas=3)\n",
        "print(\"Etiquetas detectadas:\", resultado)\n"
      ],
      "metadata": {
        "id": "I26kTKP5wS2B",
        "outputId": "b4ef002c-8a28-4e07-f484-f7cbc3a67741",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas detectadas: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "archivos_permitidos = [\n",
        "    item for item in data.get(\"value\", [])\n",
        "    if \"folder\" not in item and item[\"name\"].split(\".\")[-1].lower() in ext_permitidas\n",
        "]\n",
        "\n",
        "archivos_a_procesar = archivos_permitidos[:3]\n",
        "\n",
        "if archivos_a_procesar:\n",
        "    resultados = {}\n",
        "\n",
        "    for item in archivos_a_procesar:\n",
        "        nombre = item[\"name\"]\n",
        "        download_url = item[\"@microsoft.graph.downloadUrl\"]\n",
        "\n",
        "        print(f\"Procesando archivo: {nombre}\")\n",
        "\n",
        "        file_bytes = requests.get(download_url).content\n",
        "        texto = leer_archivo(item)\n",
        "        texto = limpiar_texto(texto)\n",
        "\n",
        "        if texto:\n",
        "            etiquetas_detectadas = etiquetar_texto(texto,etiquetas)\n",
        "        else:\n",
        "            etiquetas_detectadas = []\n",
        "\n",
        "        resultados[nombre] = etiquetas_detectadas\n",
        "        print(f\"{nombre} ‚Üí {etiquetas_detectadas}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-UdACXhq7Y",
        "outputId": "95d9023c-ccd1-414c-e392-fdb96eb5fc94"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando archivo: 11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf\n",
            "Error descargando 11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf: 401 Client Error: Unauthorized for url: https://my.microsoftpersonalcontent.com/personal/9f68595d59f0b70b/_layouts/15/download.aspx?UniqueId=c1bb0c8d-9040-4e3f-8ae9-2438b23c4747&Translate=false&tempauth=v1e.eyJzaXRlaWQiOiJjMjFhZmM2OC0xNDUxLTQyODEtOTNjYy0yOGZhNDQ4M2Y4YmIiLCJhcHBfZGlzcGxheW5hbWUiOiJFdGlxdWV0YXMiLCJhcHBpZCI6ImUzZjIzOTNlLTczNDgtNDdkMS05YzY0LThkOGVmZTZhNWU5NSIsImF1ZCI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMC9teS5taWNyb3NvZnRwZXJzb25hbGNvbnRlbnQuY29tQDkxODgwNDBkLTZjNjctNGM1Yi1iMTEyLTM2YTMwNGI2NmRhZCIsImV4cCI6IjE3NjEwODU0NjUifQ.9sjufW-qidW4TD3KItOnzuH7R-27udgacNMAkFlgUifxAf-KIFhLb5LQm8gfFhsYnCqO7uhWr8u3jR8FlpD1F6CnycCUw6E2YcR0oXK-kqFH2vuh9yaVw63ka3fArZzDyViZH4QRu6S0JludlTTbhjUENdo4njyBkktm3_eBa8RmeiGmBxavmbFyzHdmmhLIgul4wn-2zmRDq0VL-rnmRxtqFUe75d-37B-UJFVDDcBjS8RS1QPCfoxgA4W6mT8WEuQxpcdD5N6AIfM2Uy8EZfKMIJT1peljMVjby6XWABnBhtsKHYIgvnampgg5OlSnbjxHC-s9YtbmEyFqOo9QD6sse8JlNLf5KTgDcwTn73ChxnIt4IFmsWi6eI7cff1-38e4lKghvdcbwLRK45RLMc1p5B1xNH7WNACkmTQBrCHlSfUi5NPQcjRMm_TFUct6X12p_pa8lD1Bb_hFe_0XPg.Eam12muIsAmqa_-5IqPQmd9i7lu6kBSkB3r4ADe16Dc&ApiVersion=2.0\n",
            "11_07_2019_modelo_orientativo_de_contrato_de_arrendamiento_de_vivienda.pdf ‚Üí []\n",
            "Procesando archivo: 2016-admitidos_Segundo ciclo- Cursos monogr√°ficos.xls\n",
            "Error descargando 2016-admitidos_Segundo ciclo- Cursos monogr√°ficos.xls: 401 Client Error: Unauthorized for url: https://my.microsoftpersonalcontent.com/personal/9f68595d59f0b70b/_layouts/15/download.aspx?UniqueId=78aae573-4f90-4067-84d2-5ad06797bcc6&Translate=false&tempauth=v1e.eyJzaXRlaWQiOiJjMjFhZmM2OC0xNDUxLTQyODEtOTNjYy0yOGZhNDQ4M2Y4YmIiLCJhcHBfZGlzcGxheW5hbWUiOiJFdGlxdWV0YXMiLCJhcHBpZCI6ImUzZjIzOTNlLTczNDgtNDdkMS05YzY0LThkOGVmZTZhNWU5NSIsImF1ZCI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMC9teS5taWNyb3NvZnRwZXJzb25hbGNvbnRlbnQuY29tQDkxODgwNDBkLTZjNjctNGM1Yi1iMTEyLTM2YTMwNGI2NmRhZCIsImV4cCI6IjE3NjEwODU0NjUifQ.TidARwspWUSiq7_QGCJ9lVpIKkYHcg_mok3w44ruZe1jaeDkcicx21gM28LMffL-wAf5a8VYMlO_65PmQJU85QoRe0O1KaOqVOA_HUZBWSKjvXkguh2DtQ7TtB3zmEqKc2GY_GbVrAFwqr9NHVNA7j_ruwXW6rATesZ9bTR0TKkQ4eUMqhjhmfBJOCmvt5UoPt24Ju9DCa-v5DoGm01iMektpwuZ5fvKlYaCH4vA9Pjgu9ZnDP2HfPf1XjofaX424jZ_eOLSRfA2y_rAJSqqHoRLJRE20SoWRzy_aJd4qafQd_owKnzRzSwPhtCQNXTFFDK8NR_VFawGl42JmX8NmWLp05_zxslvcZqym3wqJ9MHcar2nzRbB1yKblWSc8ITfF9Veh8PJpk_F9OXtNlAletdg9P9sJaE01oM87BKg7dcQ7iAfbwuY5d3_RtmkW1fH-JERJ7zwc5FKGx-jDe8pw.da5SGTJz0_LfrEAM2E4hbuKGMh0UMV__Zl_B7F-OCq0&ApiVersion=2.0\n",
            "2016-admitidos_Segundo ciclo- Cursos monogr√°ficos.xls ‚Üí []\n",
            "Procesando archivo: 2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx\n",
            "Error descargando 2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx: 401 Client Error: Unauthorized for url: https://my.microsoftpersonalcontent.com/personal/9f68595d59f0b70b/_layouts/15/download.aspx?UniqueId=c776b69a-0375-4771-b022-1ba01443bd62&Translate=false&tempauth=v1e.eyJzaXRlaWQiOiJjMjFhZmM2OC0xNDUxLTQyODEtOTNjYy0yOGZhNDQ4M2Y4YmIiLCJhcHBfZGlzcGxheW5hbWUiOiJFdGlxdWV0YXMiLCJhcHBpZCI6ImUzZjIzOTNlLTczNDgtNDdkMS05YzY0LThkOGVmZTZhNWU5NSIsImF1ZCI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMC9teS5taWNyb3NvZnRwZXJzb25hbGNvbnRlbnQuY29tQDkxODgwNDBkLTZjNjctNGM1Yi1iMTEyLTM2YTMwNGI2NmRhZCIsImV4cCI6IjE3NjEwODU0NjUifQ.S0wBIrhhYHznAxyHv8Qb2nvvacHzc53uvtEQm2JmdbBtrmFpQSK5iGA9h9RDA5Yca4R52T-8Ar0aZdzkSGhPR9K_whyhc4dOImXwZQl_8jAu_r2SQ2B6HsZbLAzmd5GajghBLmNDmZmeP-_xkWyCy8RBwZ6JV7rxj6kWWsq4dodJB5Vn3RsJ9hFRVqIMcUzQsHeygOcZPySsFZhhhO996qayljPk7TZCLU9C-BwTas9QHgM77sHx9dVCOG62Gil8oT2RzDlJaZd0cXMkI1F0T7_rnBHqPAo-6IHUksIz1vdVb-GljiXReoJmx0p2tlinoCBVGBQQNu4UCyB3m5pdWs4AXHXjbwpjH7IZ-ikjN1pw-bhBPdFjTWa_1AG0Qw3nSIjxSJnI_TLddGFHwQ5zHMaRQSmrTLkwz8fm6rVf4AaJsY8yb0TgIVvLQ9C-AvgiTE8HKg3mvcNSuF6XHhF08Q._wpaRXXYwJ1PtFNLPSkh5nVZ9I3LvGNkYLP4Ozx6fm0&ApiVersion=2.0\n",
            "2023_05-Modelo_Documento_reserva_inmueble_en_alquiler_v.reducida.docx ‚Üí []\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}